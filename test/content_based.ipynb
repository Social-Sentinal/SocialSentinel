{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data import info_url,posts_url,reels_url,hashtags_url\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected data from different API calls\n",
    "info_data = requests.get(info, headers=headers, params=querystring).json()\n",
    "posts_data = requests.get(post, headers=headers, params=querystring).json()\n",
    "reels_data = requests.get(reels, headers=headers, params=querystring).json()\n",
    "hashtags_data = requests.get(\n",
    "    hastag, headers=headers, params=querystring).json()\n",
    "\n",
    "# Converting the collected data into DataFrames\n",
    "info_df = pd.DataFrame(info_data['data'])\n",
    "posts_df = pd.DataFrame(posts_data['data'])\n",
    "reels_df = pd.DataFrame(reels_data['data'])\n",
    "hashtags_df = pd.DataFrame(hashtags_data['data'])\n",
    "\n",
    "# Save the datasets if needed\n",
    "info_df.to_csv(\"info_data.csv\", index=False)\n",
    "posts_df.to_csv(\"posts_data.csv\", index=False)\n",
    "reels_df.to_csv(\"reels_data.csv\", index=False)\n",
    "hashtags_df.to_csv(\"hashtags_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "posts_df.drop_duplicates(inplace=True)\n",
    "reels_df.drop_duplicates(inplace=True)\n",
    "hashtags_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values or remove rows with missing data\n",
    "posts_df.fillna('', inplace=True)\n",
    "reels_df.fillna('', inplace=True)\n",
    "hashtags_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Removing URLs and special characters\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "posts_df['caption'] = posts_df['caption'].apply(clean_text)\n",
    "reels_df['caption'] = reels_df['caption'].apply(clean_text)\n",
    "hashtags_df['hashtags'] = hashtags_df['hashtags'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all datasets into a single DataFrame\n",
    "final_data = pd.merge(posts_df[['caption', 'url']], reels_df[[\n",
    "                      'caption', 'url']], on='url', how='outer')\n",
    "final_data = pd.merge(\n",
    "    final_data, hashtags_df[['hashtags', 'url']], on='url', how='outer')\n",
    "\n",
    "# Combine captions and hashtags for a complete content-based recommendation\n",
    "final_data['content'] = final_data['caption'] + \" \" + final_data['hashtags']\n",
    "\n",
    "# Drop any remaining duplicates or nulls\n",
    "final_data.drop_duplicates(subset='url', inplace=True)\n",
    "final_data.dropna(subset=['content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional because hamne pahle hi nikala hai\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score['compound']\n",
    "\n",
    "\n",
    "final_data['sentiment'] = final_data['content'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorizing the text content\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(final_data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to recommend based on content\n",
    "def get_recommendations(index, cosine_sim=cosine_sim):\n",
    "    # Get the pairwise similarity scores of all content\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "\n",
    "    # Sort content based on similarity score\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the top 10 most similar content\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Return the URLs of the most similar content\n",
    "    content_indices = [i[0] for i in sim_scores]\n",
    "    return final_data['url'].iloc[content_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recommendation system for the first post\n",
    "print(get_recommendations(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "# Save the cosine similarity matrix\n",
    "with open('cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_sim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Exploring the mountains</td>\n",
       "      <td>#sunset</td>\n",
       "      <td>339</td>\n",
       "      <td>61</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Coffee time</td>\n",
       "      <td>#morning</td>\n",
       "      <td>706</td>\n",
       "      <td>68</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Love this beach</td>\n",
       "      <td>#blessed</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>City lights</td>\n",
       "      <td>#travel</td>\n",
       "      <td>58</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>Road trip</td>\n",
       "      <td>#blessed</td>\n",
       "      <td>720</td>\n",
       "      <td>57</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  user_id                  caption  hashtags  likes  comments  \\\n",
       "0        1       15  Exploring the mountains   #sunset    339        61   \n",
       "1        2        3              Coffee time  #morning    706        68   \n",
       "2        3       11          Love this beach  #blessed    317        41   \n",
       "3        4       14              City lights   #travel     58        89   \n",
       "4        5       18                Road trip  #blessed    720        57   \n",
       "\n",
       "            timestamp  \n",
       "0 2024-01-01 00:00:00  \n",
       "1 2024-01-01 01:00:00  \n",
       "2 2024-01-01 02:00:00  \n",
       "3 2024-01-01 03:00:00  \n",
       "4 2024-01-01 04:00:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Function to create synthetic dataset\n",
    "\n",
    "\n",
    "def create_synthetic_data(num_samples=1000):\n",
    "    data = {\n",
    "        'user_id': [],\n",
    "        'post_id': [],\n",
    "        'Username': [],\n",
    "        'Caption': [],\n",
    "        'Hashtags': [],\n",
    "        'Likes': [],\n",
    "        'Comments': []\n",
    "    }\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Generate user data\n",
    "        user_id = random.randint(0, 1000)\n",
    "        post_id = random.randint(0, 1000)\n",
    "        username = fake.user_name()\n",
    "        caption = fake.sentence(nb_words=random.randint(5, 15))\n",
    "        hashtags = ' '.join([fake.word() for _ in range(random.randint(1, 5))])\n",
    "        likes = random.randint(0, 1000)\n",
    "        comments = random.randint(0, 200)\n",
    "\n",
    "        # Append data\n",
    "        data['user_id'].append(user_id)\n",
    "        data['post_id'].append(user_id)\n",
    "        data['Username'].append(username)\n",
    "        data['Caption'].append(caption)\n",
    "        data['Hashtags'].append(hashtags)\n",
    "        data['Likes'].append(likes)\n",
    "        data['Comments'].append(comments)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Create synthetic dataset\n",
    "synthetic_data = create_synthetic_data(num_samples=1000)\n",
    "\n",
    "# Save to CSV\n",
    "synthetic_data.to_csv('sentiments.csv', index=False)\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset\n",
    "synthetic_data = create_synthetic_data(num_samples=1000)\n",
    "\n",
    "# Save to CSV\n",
    "synthetic_data.to_csv('sentiments.csv', index=False)\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>share</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#healthy</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#summer</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>106</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Road trip</td>\n",
       "      <td>#roadtrip</td>\n",
       "      <td>676</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Exploring the mountains</td>\n",
       "      <td>#hiking</td>\n",
       "      <td>460</td>\n",
       "      <td>47</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>Family time</td>\n",
       "      <td>#qualitytime</td>\n",
       "      <td>360</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>19</td>\n",
       "      <td>Enjoying the sunset</td>\n",
       "      <td>#sunset</td>\n",
       "      <td>895</td>\n",
       "      <td>43</td>\n",
       "      <td>98</td>\n",
       "      <td>2024-02-11 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>15</td>\n",
       "      <td>Healthy living</td>\n",
       "      <td>#fitness</td>\n",
       "      <td>363</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-02-11 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>13</td>\n",
       "      <td>Coffee time</td>\n",
       "      <td>#caffeine</td>\n",
       "      <td>645</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>2024-02-11 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>8</td>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#food</td>\n",
       "      <td>337</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>2024-02-11 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#throwback</td>\n",
       "      <td>451</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-02-11 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id  user_id                  caption      hashtags  likes  comments  \\\n",
       "0          1        2        Healthy breakfast      #healthy    542        24   \n",
       "1          2        2      Throwback to summer       #summer    595        25   \n",
       "2          3       14                Road trip     #roadtrip    676        21   \n",
       "3          4       17  Exploring the mountains       #hiking    460        47   \n",
       "4          5        9              Family time  #qualitytime    360        31   \n",
       "..       ...      ...                      ...           ...    ...       ...   \n",
       "995      996       19      Enjoying the sunset       #sunset    895        43   \n",
       "996      997       15           Healthy living      #fitness    363        10   \n",
       "997      998       13              Coffee time     #caffeine    645        13   \n",
       "998      999        8        Healthy breakfast         #food    337        43   \n",
       "999     1000        7      Throwback to summer    #throwback    451        37   \n",
       "\n",
       "     share            timestamp  \n",
       "0       89  2024-01-01 00:00:00  \n",
       "1      106  2024-01-01 01:00:00  \n",
       "2      102  2024-01-01 02:00:00  \n",
       "3       89  2024-01-01 03:00:00  \n",
       "4       33  2024-01-01 04:00:00  \n",
       "..     ...                  ...  \n",
       "995     98  2024-02-11 11:00:00  \n",
       "996     35  2024-02-11 12:00:00  \n",
       "997     98  2024-02-11 13:00:00  \n",
       "998     46  2024-02-11 14:00:00  \n",
       "999     24  2024-02-11 15:00:00  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sentiments.csv')\n",
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv('sentiments.csv')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Keep only relevant columns (Caption, Hashtags)\n",
    "df = df[['caption', 'hashtags']]\n",
    "\n",
    "# Remove any missing or NaN values\n",
    "df.dropna(subset=['caption', 'hashtags'], inplace=True)\n",
    "\n",
    "# Step 3: Sentiment Analysis Function\n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity  # Returns a score between -1 and 1\n",
    "\n",
    "\n",
    "# Step 4: Calculate Sentiment Scores for Caption and Hashtags\n",
    "df['caption_score'] = df['Caption'].apply(analyze_sentiment)\n",
    "df['hashtag_score'] = df['Hashtags'].apply(analyze_sentiment)\n",
    "\n",
    "# Step 5: Combine Scores to Determine Overall Sentiment\n",
    "df['overall_score'] = (df['caption_score'] + df['hashtag_score']) / 2\n",
    "\n",
    "# Step 6: Categorize Sentiment\n",
    "\n",
    "\n",
    "def categorize_sentiment(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "\n",
    "df['sentiment'] = df['overall_score'].apply(categorize_sentiment)\n",
    "\n",
    "# Step 7: Create a new DataFrame with required columns\n",
    "final_df = df[['Caption', 'Hashtags', 'sentiment', 'overall_score']]\n",
    "\n",
    "# Step 8: Save to a new CSV file\n",
    "final_df.to_csv('instagram_reach_with_sentiments.csv', index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete! New file saved as 'instagram_sentiments.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#healthy</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#summer</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road trip</td>\n",
       "      <td>#roadtrip</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exploring the mountains</td>\n",
       "      <td>#hiking</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Family time</td>\n",
       "      <td>#qualitytime</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Enjoying the sunset</td>\n",
       "      <td>#sunset</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Healthy living</td>\n",
       "      <td>#fitness</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Coffee time</td>\n",
       "      <td>#caffeine</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#food</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#throwback</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     caption      hashtags sentiment  overall_score\n",
       "0          Healthy breakfast      #healthy  Positive           0.50\n",
       "1        Throwback to summer       #summer   Neutral           0.00\n",
       "2                  Road trip     #roadtrip   Neutral           0.00\n",
       "3    Exploring the mountains       #hiking   Neutral           0.00\n",
       "4                Family time  #qualitytime   Neutral           0.00\n",
       "..                       ...           ...       ...            ...\n",
       "995      Enjoying the sunset       #sunset  Positive           0.25\n",
       "996           Healthy living      #fitness  Positive           0.25\n",
       "997              Coffee time     #caffeine   Neutral           0.00\n",
       "998        Healthy breakfast         #food  Positive           0.25\n",
       "999      Throwback to summer    #throwback   Neutral           0.00\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"instagram_reach_with_sentiments.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['caption', 'hashtags', 'sentiment', 'overall_score'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caption          1000\n",
       "Hashtags          982\n",
       "sentiment           3\n",
       "overall_score     332\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('instagram_reach_with_sentiments.csv')\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    520\n",
       "Neutral     248\n",
       "Negative    232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis complete! New file saved as 'instagram_reach_with_sentiments.csv'.\n",
      "Original training set shape: Counter({'Neutral': 453, 'Negative': 189, 'Positive': 158})\n",
      "Balanced training set shape: Counter({'Neutral': 453, 'Positive': 453, 'Negative': 453})\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        48\n",
      "     Neutral       1.00      1.00      1.00       113\n",
      "    Positive       1.00      1.00      1.00        39\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Using Random Forest for better accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv('sentiments.csv')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Keep only relevant columns (Caption, Hashtags)\n",
    "df = df[['caption', 'hashtags']]\n",
    "\n",
    "# Remove any missing or NaN values\n",
    "df.dropna(subset=['caption', 'hashtags'], inplace=True)\n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "\n",
    "# Step 4: Calculate Sentiment Scores for Caption and Hashtags\n",
    "df['caption_score'] = df['caption'].apply(analyze_sentiment)\n",
    "df['hashtag_score'] = df['hashtags'].apply(analyze_sentiment)\n",
    "\n",
    "# Step 5: Combine Scores to Determine Overall Sentiment\n",
    "df['overall_score'] = (df['caption_score'] + df['hashtag_score']) / 2\n",
    "\n",
    "# Step 6: Categorize Sentiment\n",
    "\n",
    "\n",
    "def categorize_sentiment(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "\n",
    "df['sentiment'] = df['overall_score'].apply(categorize_sentiment)\n",
    "\n",
    "# Step 7: Create a new DataFrame with required columns\n",
    "final_df = df[['caption', 'hashtags', 'sentiment', 'overall_score']]\n",
    "\n",
    "# Step 8: Save to a new CSV file\n",
    "final_df.to_csv('instagram_reach_with_sentiments.csv', index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete! New file saved as 'instagram_reach_with_sentiments.csv'.\")\n",
    "\n",
    "# Load the new CSV file for training the model\n",
    "df = pd.read_csv('instagram_reach_with_sentiments.csv')\n",
    "\n",
    "# Prepare Data for Machine Learning\n",
    "X = df['caption'] + \" \" + df['hashtags']  # Features (text data)\n",
    "y = df['sentiment']  # Labels (sentiment categories)\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert Text Data into Numerical Features\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Use Random Over Sampling to Balance Classes\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Original training set shape:\", Counter(y_train))\n",
    "print(\"Balanced training set shape:\", Counter(y_train_balanced))\n",
    "\n",
    "# Train a Machine Learning Model (Random Forest Classifier)\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Save the model and the TF-IDF vectorizer\n",
    "with open('sentiment_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(tfidf, vectorizer_file)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Make Predictions on New Data\n",
    "def predict_sentiment(new_caption, new_hashtags):\n",
    "    # Load the model and vectorizer\n",
    "    with open('sentiment_model.pkl', 'rb') as model_file:\n",
    "        loaded_model = pickle.load(model_file)\n",
    "\n",
    "    with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "        loaded_vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "    new_text = new_caption + \" \" + new_hashtags\n",
    "    new_tfidf = loaded_vectorizer.transform([new_text])\n",
    "    return loaded_model.predict(new_tfidf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'i love this product' - Sentiment: Positive\n",
      "Text: 'this product is terrible' - Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the Random Forest model\n",
    "with open('sentiment_model.pkl', 'rb') as random_forest_model_file:\n",
    "    random_forest_model = pickle.load(random_forest_model_file)\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "    tfidf_vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "# # Define the test data\n",
    "# test_data = pd.DataFrame(\n",
    "#     {'text': ['I love this product', 'This product is terrible']})\n",
    "\n",
    "# give as user input \n",
    "\n",
    "# Preprocess the text data\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "test_data['text'] = test_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize the preprocessed text data\n",
    "X_test = tfidf_vectorizer.transform(test_data['text'])\n",
    "\n",
    "# Make predictions\n",
    "predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "# Print the results\n",
    "for text, prediction in zip(test_data['text'], predictions):\n",
    "    print(f\"Text: '{text}' - Sentiment: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the Random Forest model and TF-IDF vectorizer\n",
    "with open('sentiment_model.pkl', 'rb') as model_file:\n",
    "    random_forest_model = pickle.load(model_file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "    tfidf_vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "# Preprocess the text data\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')  # Render the input form\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    user_input = request.form['text']  # Get the user input from the form\n",
    "    # Create a DataFrame for the input\n",
    "    test_data = pd.DataFrame({'text': [user_input]})\n",
    "\n",
    "    # Apply preprocessing\n",
    "    test_data['text'] = test_data['text'].apply(preprocess_text)\n",
    "\n",
    "    # Vectorize the preprocessed text data\n",
    "    X_test = tfidf_vectorizer.transform(test_data['text'])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "    # Return the result\n",
    "    return jsonify({'text': user_input, 'sentiment': predictions[0]})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#healthy</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#summer</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road trip</td>\n",
       "      <td>#roadtrip</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exploring the mountains</td>\n",
       "      <td>#hiking</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Family time</td>\n",
       "      <td>#qualitytime</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Enjoying the sunset</td>\n",
       "      <td>#sunset</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Healthy living</td>\n",
       "      <td>#fitness</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Coffee time</td>\n",
       "      <td>#caffeine</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#food</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#throwback</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     caption      hashtags sentiment  overall_score\n",
       "0          Healthy breakfast      #healthy  Positive           0.50\n",
       "1        Throwback to summer       #summer   Neutral           0.00\n",
       "2                  Road trip     #roadtrip   Neutral           0.00\n",
       "3    Exploring the mountains       #hiking   Neutral           0.00\n",
       "4                Family time  #qualitytime   Neutral           0.00\n",
       "..                       ...           ...       ...            ...\n",
       "995      Enjoying the sunset       #sunset  Positive           0.25\n",
       "996           Healthy living      #fitness  Positive           0.25\n",
       "997              Coffee time     #caffeine   Neutral           0.00\n",
       "998        Healthy breakfast         #food  Positive           0.25\n",
       "999      Throwback to summer    #throwback   Neutral           0.00\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('instagram_reach_with_sentiments.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Neutral     566\n",
       "Negative    237\n",
       "Positive    197\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "new_caption = \"I am sad\"\n",
    "new_hashtags = \"#sad\"\n",
    "predicted_sentiment = predict_sentiment(new_caption, new_hashtags)\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data lists for captions and hashtags (with logical associations)\n",
    "caption_hashtag_pairs = {\n",
    "    \"Enjoying the sunset\": [\"#sunset\", \"#evening\", \"#nature\"],\n",
    "    \"Morning vibes\": [\"#morning\", \"#freshstart\", \"#sunrise\"],\n",
    "    \"Love this beach\": [\"#beach\", \"#ocean\", \"#sun\"],\n",
    "    \"Hiking adventures\": [\"#hiking\", \"#outdoors\", \"#adventure\"],\n",
    "    \"Coffee time\": [\"#coffee\", \"#morning\", \"#caffeine\"],\n",
    "    \"Feeling blessed\": [\"#blessed\", \"#grateful\", \"#thankful\"],\n",
    "    \"Weekend getaway\": [\"#weekend\", \"#travel\", \"#getaway\"],\n",
    "    \"Road trip\": [\"#roadtrip\", \"#adventure\", \"#travel\"],\n",
    "    \"Exploring the mountains\": [\"#mountains\", \"#hiking\", \"#nature\"],\n",
    "    \"City lights\": [\"#city\", \"#nightlife\", \"#urban\"],\n",
    "    \"Healthy living\": [\"#healthyliving\", \"#fitness\", \"#wellness\"],\n",
    "    \"Family time\": [\"#family\", \"#love\", \"#qualitytime\"],\n",
    "    \"Throwback to summer\": [\"#summer\", \"#memories\", \"#throwback\"],\n",
    "    \"Dinner with friends\": [\"#dinner\", \"#friends\", \"#goodtimes\"],\n",
    "    \"Workout motivation\": [\"#workout\", \"#fitness\", \"#motivation\"],\n",
    "    \"Chasing waterfalls\": [\"#waterfalls\", \"#nature\", \"#hiking\"],\n",
    "    \"Sunset views\": [\"#sunset\", \"#views\", \"#sky\"],\n",
    "    \"Beach day\": [\"#beach\", \"#sun\", \"#sand\"],\n",
    "    \"Healthy breakfast\": [\"#breakfast\", \"#healthy\", \"#food\"],\n",
    "    \"Travel goals\": [\"#travel\", \"#adventure\", \"#explore\"],\n",
    "    \"I am feeling very sad\":[\"#sad\",\"#low\",\"#feel\"],\n",
    "    \"it makes me sad\":[\"#depression\",\"#stress\",\"#trauma\"],\n",
    "    \"the sad fact is that he's lost his touch\" : [\"#lost\",\"#touch\",\"#sad\"],\n",
    "    \"they looked at her with sad, anxious faces\" : [\"#anxious\",\"#sad\",\"#faces\"],\n",
    "    \"I am feeling very happy\":[\"#happy\",\"#joy\",\"#feel\"],\n",
    "    \"the sad fact is that he's lost his touch\" : [\"#lost\",\"#touch\",\"#sad\"],\n",
    "    \"they looked at her with sad, anxious faces\" : [\"#anxious\",\"#sad\",\"#faces\"],\n",
    "    \"a sad day for us all\":[\"#sad\",\"#day\",\"#all\"],\n",
    "    \"sad to say, she never lived to see it\":[\"#lived\",\"sad\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate users with varying engagement patterns\n",
    "users = {\n",
    "    1: {'activity_level': 'high', 'avg_likes': 800, 'avg_comments': 50},\n",
    "    2: {'activity_level': 'medium', 'avg_likes': 500, 'avg_comments': 30},\n",
    "    3: {'activity_level': 'low', 'avg_likes': 200, 'avg_comments': 10},\n",
    "    4: {'activity_level': 'high', 'avg_likes': 700, 'avg_comments': 40},\n",
    "    5: {'activity_level': 'medium', 'avg_likes': 400, 'avg_comments': 25},\n",
    "    6: {'activity_level': 'low', 'avg_likes': 150, 'avg_comments': 5},\n",
    "    7: {'activity_level': 'high', 'avg_likes': 900, 'avg_comments': 60},\n",
    "    8: {'activity_level': 'medium', 'avg_likes': 450, 'avg_comments': 20},\n",
    "    9: {'activity_level': 'low', 'avg_likes': 180, 'avg_comments': 8},\n",
    "    10: {'activity_level': 'high', 'avg_likes': 750, 'avg_comments': 45},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand user pool up to 20 with varied activity levels\n",
    "for user_id in range(4, 21):\n",
    "    users[user_id] = {\n",
    "        'activity_level': random.choice(['high', 'medium', 'low']),\n",
    "        'avg_likes': random.randint(200, 800),\n",
    "        'avg_comments': random.randint(10, 50),\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of posts\n",
    "n = 1000\n",
    "\n",
    "# Generate random posts with relationships between columns\n",
    "data = {\n",
    "    'post_id': [i for i in range(1, n+1)],\n",
    "    # Random user IDs from 1 to 20\n",
    "    'user_id': [random.randint(1, 20) for _ in range(n)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic captions, hashtags, likes, comments, and timestamps\n",
    "captions = []\n",
    "hashtags = []\n",
    "likes = []\n",
    "comments = []\n",
    "share = []\n",
    "timestamps = pd.date_range(start='2024-01-01', periods=n, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    user_id = data['user_id'][i]\n",
    "\n",
    "    # Choose a random caption and corresponding hashtag\n",
    "    caption = random.choice(list(caption_hashtag_pairs.keys()))\n",
    "    hashtags_list = caption_hashtag_pairs[caption]\n",
    "    hashtag = random.choice(hashtags_list)\n",
    "\n",
    "    # Likes and comments depend on user's activity level\n",
    "    user_profile = users[user_id]\n",
    "    base_likes = user_profile['avg_likes']\n",
    "    base_comments = user_profile['avg_comments']\n",
    "\n",
    "    # Add some variability (more likes and comments for certain captions or time of day)\n",
    "    # Evening posts get more likes\n",
    "    engagement_factor = 1.5 if \"sunset\" in caption or timestamps[i].hour >= 18 else 1\n",
    "    post_likes = int(base_likes * engagement_factor *\n",
    "                     random.uniform(0.8, 1.2))  # Add randomness\n",
    "    share_count = int(post_likes * random.uniform(0.05, 0.2))\n",
    "    post_comments = int(base_comments * engagement_factor *\n",
    "                        random.uniform(0.8, 1.2))\n",
    "    \n",
    "\n",
    "    # Append to lists\n",
    "    captions.append(caption)\n",
    "    hashtags.append(hashtag)\n",
    "    likes.append(post_likes)\n",
    "    share.append(share_count)\n",
    "    comments.append(post_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>share</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#healthy</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#summer</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>106</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Road trip</td>\n",
       "      <td>#roadtrip</td>\n",
       "      <td>676</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Exploring the mountains</td>\n",
       "      <td>#hiking</td>\n",
       "      <td>460</td>\n",
       "      <td>47</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>Family time</td>\n",
       "      <td>#qualitytime</td>\n",
       "      <td>360</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  user_id                  caption      hashtags  likes  comments  \\\n",
       "0        1        2        Healthy breakfast      #healthy    542        24   \n",
       "1        2        2      Throwback to summer       #summer    595        25   \n",
       "2        3       14                Road trip     #roadtrip    676        21   \n",
       "3        4       17  Exploring the mountains       #hiking    460        47   \n",
       "4        5        9              Family time  #qualitytime    360        31   \n",
       "\n",
       "   share           timestamp  \n",
       "0     89 2024-01-01 00:00:00  \n",
       "1    106 2024-01-01 01:00:00  \n",
       "2    102 2024-01-01 02:00:00  \n",
       "3     89 2024-01-01 03:00:00  \n",
       "4     33 2024-01-01 04:00:00  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add to the data dictionary\n",
    "data['caption'] = captions\n",
    "data['hashtags'] = hashtags\n",
    "data['likes'] = likes\n",
    "data['comments'] = comments\n",
    "data['share'] = share\n",
    "data['timestamp'] = timestamps\n",
    "\n",
    "# Create DataFrame\n",
    "instagram_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "instagram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caption\n",
       "a sad day for us all                          46\n",
       "Sunset views                                  46\n",
       "it makes me sad                               45\n",
       "Coffee time                                   43\n",
       "Travel goals                                  43\n",
       "I am feeling very sad                         42\n",
       "Hiking adventures                             41\n",
       "Feeling blessed                               41\n",
       "Dinner with friends                           41\n",
       "the sad fact is that he's lost his touch      39\n",
       "Healthy breakfast                             38\n",
       "Love this beach                               38\n",
       "Road trip                                     38\n",
       "sad to say, she never lived to see it         37\n",
       "Enjoying the sunset                           37\n",
       "Healthy living                                37\n",
       "Family time                                   36\n",
       "Workout motivation                            35\n",
       "Morning vibes                                 33\n",
       "I am feeling very happy                       32\n",
       "Chasing waterfalls                            32\n",
       "Beach day                                     32\n",
       "City lights                                   32\n",
       "Exploring the mountains                       31\n",
       "Throwback to summer                           30\n",
       "they looked at her with sad, anxious faces    28\n",
       "Weekend getaway                               27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instagram_df['caption'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instagram_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_df.to_csv('sentiments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>share</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#healthy</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#summer</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>106</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Road trip</td>\n",
       "      <td>#roadtrip</td>\n",
       "      <td>676</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Exploring the mountains</td>\n",
       "      <td>#hiking</td>\n",
       "      <td>460</td>\n",
       "      <td>47</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>Family time</td>\n",
       "      <td>#qualitytime</td>\n",
       "      <td>360</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>19</td>\n",
       "      <td>Enjoying the sunset</td>\n",
       "      <td>#sunset</td>\n",
       "      <td>895</td>\n",
       "      <td>43</td>\n",
       "      <td>98</td>\n",
       "      <td>2024-02-11 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>15</td>\n",
       "      <td>Healthy living</td>\n",
       "      <td>#fitness</td>\n",
       "      <td>363</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-02-11 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>13</td>\n",
       "      <td>Coffee time</td>\n",
       "      <td>#caffeine</td>\n",
       "      <td>645</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>2024-02-11 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>8</td>\n",
       "      <td>Healthy breakfast</td>\n",
       "      <td>#food</td>\n",
       "      <td>337</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>2024-02-11 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>Throwback to summer</td>\n",
       "      <td>#throwback</td>\n",
       "      <td>451</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-02-11 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id  user_id                  caption      hashtags  likes  comments  \\\n",
       "0          1        2        Healthy breakfast      #healthy    542        24   \n",
       "1          2        2      Throwback to summer       #summer    595        25   \n",
       "2          3       14                Road trip     #roadtrip    676        21   \n",
       "3          4       17  Exploring the mountains       #hiking    460        47   \n",
       "4          5        9              Family time  #qualitytime    360        31   \n",
       "..       ...      ...                      ...           ...    ...       ...   \n",
       "995      996       19      Enjoying the sunset       #sunset    895        43   \n",
       "996      997       15           Healthy living      #fitness    363        10   \n",
       "997      998       13              Coffee time     #caffeine    645        13   \n",
       "998      999        8        Healthy breakfast         #food    337        43   \n",
       "999     1000        7      Throwback to summer    #throwback    451        37   \n",
       "\n",
       "     share            timestamp  \n",
       "0       89  2024-01-01 00:00:00  \n",
       "1      106  2024-01-01 01:00:00  \n",
       "2      102  2024-01-01 02:00:00  \n",
       "3       89  2024-01-01 03:00:00  \n",
       "4       33  2024-01-01 04:00:00  \n",
       "..     ...                  ...  \n",
       "995     98  2024-02-11 11:00:00  \n",
       "996     35  2024-02-11 12:00:00  \n",
       "997     98  2024-02-11 13:00:00  \n",
       "998     46  2024-02-11 14:00:00  \n",
       "999     24  2024-02-11 15:00:00  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sentiments.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
