{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I7glMHP6JEf1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('Instagram_data.csv')\n",
        "# Fill missing values in 'Caption' and 'Hashtags' columns\n",
        "df['Caption'] = df['Caption'].fillna('')\n",
        "df['Hashtags'] = df['Hashtags'].fillna('')\n",
        "# Combine Caption and Hashtags for vectorization\n",
        "df['content'] = df['Caption'] + ' ' + df['Hashtags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Impressions</th>\n",
              "      <th>From Home</th>\n",
              "      <th>From Hashtags</th>\n",
              "      <th>From Explore</th>\n",
              "      <th>From Other</th>\n",
              "      <th>Saves</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Shares</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Profile Visits</th>\n",
              "      <th>Follows</th>\n",
              "      <th>Conversion Rate</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-12-10</td>\n",
              "      <td>3920</td>\n",
              "      <td>2586</td>\n",
              "      <td>1028</td>\n",
              "      <td>619</td>\n",
              "      <td>56</td>\n",
              "      <td>98</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>162</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>5.714286</td>\n",
              "      <td>Here are some of the most important data visua...</td>\n",
              "      <td>#finance #money #business #investing #investme...</td>\n",
              "      <td>Here are some of the most important data visua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-12-11</td>\n",
              "      <td>5394</td>\n",
              "      <td>2727</td>\n",
              "      <td>1838</td>\n",
              "      <td>1174</td>\n",
              "      <td>78</td>\n",
              "      <td>194</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>224</td>\n",
              "      <td>48</td>\n",
              "      <td>10</td>\n",
              "      <td>20.833333</td>\n",
              "      <td>Here are some of the best data science project...</td>\n",
              "      <td>#healthcare #health #covid #data #datascience ...</td>\n",
              "      <td>Here are some of the best data science project...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-12-12</td>\n",
              "      <td>4021</td>\n",
              "      <td>2085</td>\n",
              "      <td>1188</td>\n",
              "      <td>0</td>\n",
              "      <td>533</td>\n",
              "      <td>41</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>131</td>\n",
              "      <td>62</td>\n",
              "      <td>12</td>\n",
              "      <td>19.354839</td>\n",
              "      <td>Learn how to train a machine learning model an...</td>\n",
              "      <td>#data #datascience #dataanalysis #dataanalytic...</td>\n",
              "      <td>Learn how to train a machine learning model an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-12-13</td>\n",
              "      <td>4528</td>\n",
              "      <td>2700</td>\n",
              "      <td>621</td>\n",
              "      <td>932</td>\n",
              "      <td>73</td>\n",
              "      <td>172</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>213</td>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "      <td>34.782609</td>\n",
              "      <td>Here’s how you can write a Python program to d...</td>\n",
              "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
              "      <td>Here’s how you can write a Python program to d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-12-14</td>\n",
              "      <td>2518</td>\n",
              "      <td>1704</td>\n",
              "      <td>255</td>\n",
              "      <td>279</td>\n",
              "      <td>37</td>\n",
              "      <td>96</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>123</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Plotting annotations while visualizing your da...</td>\n",
              "      <td>#datavisualization #datascience #data #dataana...</td>\n",
              "      <td>Plotting annotations while visualizing your da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  Impressions  From Home  From Hashtags  From Explore  \\\n",
              "0  2021-12-10         3920       2586           1028           619   \n",
              "1  2021-12-11         5394       2727           1838          1174   \n",
              "2  2021-12-12         4021       2085           1188             0   \n",
              "3  2021-12-13         4528       2700            621           932   \n",
              "4  2021-12-14         2518       1704            255           279   \n",
              "\n",
              "   From Other  Saves  Comments  Shares  Likes  Profile Visits  Follows  \\\n",
              "0          56     98         9       5    162              35        2   \n",
              "1          78    194         7      14    224              48       10   \n",
              "2         533     41        11       1    131              62       12   \n",
              "3          73    172        10       7    213              23        8   \n",
              "4          37     96         5       4    123               8        0   \n",
              "\n",
              "   Conversion Rate                                            Caption  \\\n",
              "0         5.714286  Here are some of the most important data visua...   \n",
              "1        20.833333  Here are some of the best data science project...   \n",
              "2        19.354839  Learn how to train a machine learning model an...   \n",
              "3        34.782609  Here’s how you can write a Python program to d...   \n",
              "4         0.000000  Plotting annotations while visualizing your da...   \n",
              "\n",
              "                                            Hashtags  \\\n",
              "0  #finance #money #business #investing #investme...   \n",
              "1  #healthcare #health #covid #data #datascience ...   \n",
              "2  #data #datascience #dataanalysis #dataanalytic...   \n",
              "3  #python #pythonprogramming #pythonprojects #py...   \n",
              "4  #datavisualization #datascience #data #dataana...   \n",
              "\n",
              "                                             content  \n",
              "0  Here are some of the most important data visua...  \n",
              "1  Here are some of the best data science project...  \n",
              "2  Learn how to train a machine learning model an...  \n",
              "3  Here’s how you can write a Python program to d...  \n",
              "4  Plotting annotations while visualizing your da...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "46-M1JNDKEJE",
        "outputId": "d91cb2e9-41c0-4a18-be6f-42d80b38d8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Date                                            Caption  \\\n",
            "26  2022-01-05  You must have heard or invested in any cryptoc...   \n",
            "95  2022-03-15  You must have heard or invested in any cryptoc...   \n",
            "65  2022-02-13  If you want to know how to predict the future ...   \n",
            "18  2021-12-28  Stress, anxiety, and depression are threatenin...   \n",
            "85  2022-03-05  Stress, anxiety, and depression are threatenin...   \n",
            "\n",
            "                                             Hashtags     Likes  Comments  \\\n",
            "26  #data #datascience #dataanalysis #dataanalytic...  0.037147  0.678571   \n",
            "95  #data #datascience #dataanalysis #dataanalytic...  0.037147  0.678571   \n",
            "65  #data #datascience #dataanalysis #dataanalytic...  0.011887  0.107143   \n",
            "18  #data #datascience #dataanalysis #dataanalytic...  0.039128  0.214286   \n",
            "85  #data #datascience #dataanalysis #dataanalytic...  0.039128  0.214286   \n",
            "\n",
            "      Shares  \n",
            "26  0.012712  \n",
            "95  0.012712  \n",
            "65  0.010593  \n",
            "18  0.012712  \n",
            "85  0.012712  \n"
          ]
        }
      ],
      "source": [
        "# Vectorize the content (Caption + Hashtags) using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "tfidf_matrix = tfidf.fit_transform(df['content'])\n",
        "\n",
        "# Normalize engagement metrics (Likes, Comments, Shares, etc.)\n",
        "scaler = MinMaxScaler()\n",
        "engagement_metrics = ['Likes', 'Comments', 'Shares', 'Saves', 'Profile Visits', 'Follows']\n",
        "df[engagement_metrics] = scaler.fit_transform(df[engagement_metrics])\n",
        "\n",
        "# Combine TF-IDF matrix with engagement features\n",
        "combined_features = pd.concat([pd.DataFrame(tfidf_matrix.toarray()), df[engagement_metrics].reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Compute cosine similarity matrix for the dataset\n",
        "similarity_matrix = cosine_similarity(combined_features)\n",
        "\n",
        "# Function to recommend posts based on input caption\n",
        "def recommend_by_caption(input_caption, num_recommendations=5):\n",
        "    # Preprocess input caption\n",
        "    input_caption_processed = input_caption\n",
        "\n",
        "    # Vectorize the input caption using the same TF-IDF vectorizer\n",
        "    input_caption_vector = tfidf.transform([input_caption_processed])\n",
        "\n",
        "    # Create a combined feature vector for the input (only using content for now)\n",
        "    input_combined_features = pd.concat([pd.DataFrame(input_caption_vector.toarray()),\n",
        "                                         pd.DataFrame([[0]*len(engagement_metrics)])], axis=1)\n",
        "\n",
        "    # Compute cosine similarity between the input caption and all posts in the dataset\n",
        "    similarity_scores = cosine_similarity(input_combined_features, combined_features).flatten()\n",
        "\n",
        "    # Sort the posts based on similarity scores\n",
        "    similar_posts_indices = similarity_scores.argsort()[::-1][:num_recommendations]\n",
        "\n",
        "    # Return the top N similar posts\n",
        "    return df.iloc[similar_posts_indices]\n",
        "\n",
        "# Example: Input a caption to get recommendations\n",
        "input_caption = \"stressful life can lead to many problems in future\"\n",
        "recommended_posts = recommend_by_caption(input_caption=input_caption, num_recommendations=5)\n",
        "print(recommended_posts[['Date', 'Caption', 'Hashtags', 'Likes', 'Comments', 'Shares']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Text Preprocessing function\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = [word for word in text.split() if word not in stop_words]\n",
        "    # Stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values in 'Caption' and 'Hashtags' columns\n",
        "df['Caption'] = df['Caption'].fillna('')\n",
        "df['Hashtags'] = df['Hashtags'].fillna('')\n",
        "\n",
        "# Apply text preprocessing\n",
        "df['Caption'] = df['Caption'].apply(preprocess_text)\n",
        "df['Hashtags'] = df['Hashtags'].apply(preprocess_text)\n",
        "\n",
        "# Combine Caption and Hashtags for vectorization\n",
        "df['content'] = df['Caption'] + ' ' + df['Hashtags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use TF-IDF for text vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "tfidf_matrix = tfidf.fit_transform(df['content'])\n",
        "\n",
        "# Normalize engagement metrics\n",
        "scaler = MinMaxScaler()\n",
        "engagement_metrics = ['Likes', 'Comments',\n",
        "                      'Shares', 'Saves', 'Profile Visits', 'Follows']\n",
        "df[engagement_metrics] = scaler.fit_transform(df[engagement_metrics])\n",
        "\n",
        "# Combine TF-IDF matrix with engagement features\n",
        "engagement_features = df[engagement_metrics].values\n",
        "\n",
        "# Ensure both arrays are 2D and can be concatenated\n",
        "combined_features = np.hstack([tfidf_matrix.toarray(), engagement_features])\n",
        "\n",
        "# Compute cosine similarity matrix for combined features\n",
        "similarity_matrix = cosine_similarity(combined_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to recommend posts based on input caption with more weight on engagement\n",
        "def recommend_by_caption(input_caption, num_recommendations=5, engagement_weight=0.3):\n",
        "    # Preprocess input caption\n",
        "    input_caption_processed = preprocess_text(input_caption)\n",
        "\n",
        "    # Vectorize the input caption using the same TF-IDF vectorizer\n",
        "    input_caption_vector = tfidf.transform([input_caption_processed])\n",
        "\n",
        "    # Initialize engagement metrics for input to zero and reshape to 2D\n",
        "    zeros_for_engagement = np.zeros(\n",
        "        engagement_features.shape[1]).reshape(1, -1)\n",
        "\n",
        "    # Create a combined feature vector for the input\n",
        "    input_combined_features = np.hstack(\n",
        "        [input_caption_vector.toarray(), zeros_for_engagement])\n",
        "\n",
        "    # Compute cosine similarity between input caption and all posts\n",
        "    similarity_scores = cosine_similarity(\n",
        "        input_combined_features, combined_features).flatten()\n",
        "\n",
        "    # Sort the posts based on similarity scores\n",
        "    similar_posts_indices = similarity_scores.argsort()[\n",
        "        ::-1][:num_recommendations]\n",
        "\n",
        "    # Return the top N similar posts\n",
        "    return df.iloc[similar_posts_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfit7fMwMI7y",
        "outputId": "29cdc143-6be5-4761-f28f-e75e0ce7f68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Date                                            Caption  \\\n",
            "85  2022-03-05  stress anxieti depress threaten mental health ...   \n",
            "18  2021-12-28  stress anxieti depress threaten mental health ...   \n",
            "64  2022-02-12  use python script use solv realtim problem pro...   \n",
            "1   2021-12-11  best data scienc project idea healthcar want b...   \n",
            "61  2022-02-09  best data scienc project idea healthcar want b...   \n",
            "\n",
            "                                             Hashtags     Likes  Comments  \\\n",
            "85  data datasci dataanalysi dataanalyt datascient...  0.039128  0.214286   \n",
            "18  data datasci dataanalysi dataanalyt datascient...  0.039128  0.214286   \n",
            "64  python pythonprogram pythonproject pythoncod p...  0.097573  0.250000   \n",
            "1   healthcar health covid data datasci dataanalys...  0.075285  0.250000   \n",
            "61  healthcar health covid data datasci dataanalys...  0.087172  0.285714   \n",
            "\n",
            "      Shares  \n",
            "85  0.012712  \n",
            "18  0.012712  \n",
            "64  0.025424  \n",
            "1   0.029661  \n",
            "61  0.010593  \n"
          ]
        }
      ],
      "source": [
        "# Example: Input a caption to get recommendations with improved accuracy\n",
        "input_caption = \"stressful life leads to health problems\"\n",
        "recommended_posts = recommend_by_caption(input_caption=input_caption, num_recommendations=5)\n",
        "print(recommended_posts[['Date', 'Caption', 'Hashtags', 'Likes', 'Comments', 'Shares']])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
