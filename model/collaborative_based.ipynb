{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, session\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset once\n",
    "df = pd.read_csv('Instagram_data.csv')\n",
    "df['Caption'] = df['Caption'].fillna('')\n",
    "df['Hashtags'] = df['Hashtags'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Caption'] = df['Caption'].apply(preprocess_text)\n",
    "df['Hashtags'] = df['Hashtags'].apply(preprocess_text)\n",
    "df['content'] = df['Caption'] + ' ' + df['Hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the content\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf.fit_transform(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize engagement metrics\n",
    "scaler = MinMaxScaler()\n",
    "engagement_metrics = ['Likes', 'Comments',\n",
    "                      'Shares', 'Saves', 'Profile Visits', 'Follows']\n",
    "df[engagement_metrics] = scaler.fit_transform(df[engagement_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF matrix with engagement features\n",
    "engagement_features = df[engagement_metrics].values\n",
    "combined_features = np.hstack([tfidf_matrix.toarray(), engagement_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend posts\n",
    "def recommend_by_caption(input_caption, num_recommendations=5, engagement_weight=0.3):\n",
    "    input_caption_processed = preprocess_text(input_caption)\n",
    "    input_caption_vector = tfidf.transform([input_caption_processed])\n",
    "    zeros_for_engagement = np.zeros(\n",
    "        engagement_features.shape[1]).reshape(1, -1)\n",
    "    input_combined_features = np.hstack(\n",
    "        [input_caption_vector.toarray(), zeros_for_engagement])\n",
    "    similarity_scores = cosine_similarity(\n",
    "        input_combined_features, combined_features).flatten()\n",
    "    similar_posts_indices = similarity_scores.argsort()[\n",
    "        ::-1][:num_recommendations]\n",
    "    return df.iloc[similar_posts_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = Flask(__name__)\n",
    "# app.secret_key = 'your_secret_key'  # Used for session management\n",
    "\n",
    "\n",
    "# @app.route('/recommend', methods=['GET'])\n",
    "# def recommend():\n",
    "#     user_caption = request.json.get('caption')\n",
    "#     if not user_caption:\n",
    "#         return jsonify({'error': 'Caption is required'}), 400\n",
    "\n",
    "#     # Get recommendations for the user input caption\n",
    "#     recommended_posts = recommend_by_caption(user_caption)\n",
    "\n",
    "#     # Prepare response\n",
    "#     result = recommended_posts[['Date', 'Caption', 'Hashtags',\n",
    "#                                 'Likes', 'Comments', 'Shares']].to_dict(orient='records')\n",
    "\n",
    "#     return jsonify(result), 200\n",
    "\n",
    "\n",
    "# # Run the Flask app\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Posts:\n"
     ]
    }
   ],
   "source": [
    "# Combine TF-IDF matrix with engagement features\n",
    "engagement_features = df[engagement_metrics].values\n",
    "combined_features = np.hstack([tfidf_matrix.toarray(), engagement_features])\n",
    "\n",
    "# Function to recommend posts based on input caption\n",
    "\n",
    "\n",
    "def recommend_by_caption(input_caption, num_recommendations=5, engagement_weight=0.3):\n",
    "    input_caption_processed = preprocess_text(input_caption)\n",
    "    input_caption_vector = tfidf.transform([input_caption_processed])\n",
    "    zeros_for_engagement = np.zeros(\n",
    "        engagement_features.shape[1]).reshape(1, -1)\n",
    "    input_combined_features = np.hstack(\n",
    "        [input_caption_vector.toarray(), zeros_for_engagement])\n",
    "    similarity_scores = cosine_similarity(\n",
    "        input_combined_features, combined_features).flatten()\n",
    "    similar_posts_indices = similarity_scores.argsort()[\n",
    "        ::-1][:num_recommendations]\n",
    "    return df.iloc[similar_posts_indices]\n",
    "\n",
    "\n",
    "# Main logic to take user input and give recommendations\n",
    "if __name__ == '__main__':\n",
    "    input_caption = input(\"Enter a caption to get recommendations: \")\n",
    "\n",
    "    # Get recommendations for the input caption\n",
    "    recommended_posts = recommend_by_caption(\n",
    "        input_caption=input_caption, num_recommendations=5)\n",
    "\n",
    "    # Print the recommended posts\n",
    "    print(\"\\nRecommended Posts:\")\n",
    "    # data = pd.DataFrame(recommended_posts[['Date', 'Caption',\n",
    "    #                                        'Hashtags', 'Likes', 'Comments', 'Shares']])\n",
    "    # data.head(5)\n",
    "    print(recommended_posts[['Date', 'Caption',\n",
    "          'Hashtags', 'Likes', 'Comments', 'Shares']])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
