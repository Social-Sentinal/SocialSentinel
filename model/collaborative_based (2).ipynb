{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-fOm4nrTWvU",
        "outputId": "95c6ae62-28b9-448c-d0fa-f4f424f7a252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommended Captions and Hashtags:\n",
            "Caption: We are coming up with the Best 21 Books that will change your mind about Life, Money and Your self Campaign this week!!We will post this books with genuine reviews from Amazon.com ! Hope you will enjoy this and try to read this amazing books!! Stay Tuned !! 😉❤️\n",
            "\n",
            "Hashtags: #books #book #motivation #inspiration #life#booklover #lifebook2018 #love #finance#personality #training #growth#development #musthave #instadaily#trending #sales #happy #knowledge#knowledgeispower #amazon #fiction #scifi#hotsale #art #biography  #autobiography#selfhelp  #offers\n",
            "\n",
            "Caption: Life is all about the next step💎\n",
            "\n",
            "Hashtags: #Entrepreneur#Business#Entrepreneurship#WontStop#Mindset#Success#Hustle#Freedom#BusinessOwner#OnlineBusiness#Coaching#Ambition#Inspire#ThinkBig#Startup#HardWork#Businessman#BeYourOwnBoss#SmallBusiness#Believe#Motivate#Mentor or #mentoring#Givingback#InternetBusiness#Successe\n",
            "\n",
            "Caption: Interesting, most of them prefer that because all need high accuracy. Its also implemented in real life problem. It's joke but useful. I believe it most understandable by data science enthusiast. \n",
            "\n",
            "Hashtags: #data_enthusiast #dataanalytics#datascientist #datascience #algorithm#deeplearning #machinelearning #ai#traditional #learning #neuralnetworks#aspiringdatascientist #followyourownpath\n",
            "\n",
            "Caption: Last week was pretty busy, so I had no chance to report any news 👨🏻‍💻🙃\n",
            "\n",
            "Hashtags: #design #instaphoto #inspiration#premierpro #oreo #videoediting #isetups#aftereffects #color #colorcombination#work #workspace #development#hardwork #dayout #krakow #programming#illustration #photographer #photo #life#likeforlikes #likeforfollow #followme#folow4folow #goodday #goodweek\n",
            "\n",
            "Caption: Obtén tu tienda en línea ahora.\n",
            "\n",
            "Hashtags: #marketing #programming#development #desarrollo #webdesign#diseñoweb #frontend #backend #apps#app #mobileapps #aplicaciones #españa#panama  #argentina #chile #uruguay#digitalmarketing #socialmedia#ecommerce #tiendaonline #design#startup #emprender #website #paginaweb#followme #work #business #empresa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'instagram_reach.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Combine Captions and Hashtags into a single \"Item\" column for simplicity\n",
        "df['Item'] = df['Caption'].fillna('') + \" \" + df['Hashtags'].fillna('')\n",
        "\n",
        "# Step 2: Create a pivot table (User-Item matrix) where rows are users and columns are items (captions + hashtags)\n",
        "user_item_matrix = df.pivot_table(index='USERNAME', columns='Item', values='Likes', fill_value=0)\n",
        "\n",
        "# Step 3: Use SVD for collaborative filtering\n",
        "svd = TruncatedSVD(n_components=50)  # Reduce to 50 latent factors\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "item_factors = svd.components_\n",
        "\n",
        "# Step 4: Initialize the TF-IDF vectorizer for content-based filtering\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "item_matrix = vectorizer.fit_transform(df['Item'].values.astype('U'))  # Fit on entire dataset\n",
        "\n",
        "# Function to recommend captions and hashtags based on a clicked caption\n",
        "def recommend_based_on_click(clicked_caption, df, user_item_matrix, user_factors, item_factors, vectorizer, top_n=5):\n",
        "    # Step 1: Transform the clicked caption using the TF-IDF vectorizer\n",
        "    clicked_caption_vector = vectorizer.transform([clicked_caption])\n",
        "\n",
        "    # Step 2: Calculate content similarity between the clicked caption and the items in the dataset\n",
        "    content_similarity_scores = cosine_similarity(clicked_caption_vector, item_matrix).flatten()\n",
        "\n",
        "    # Step 3: Get the indices of the most similar captions based on content\n",
        "    content_top_indices = content_similarity_scores.argsort()[-(top_n+1):-1][::-1]\n",
        "    content_based_recommendations = df.iloc[content_top_indices][['Caption', 'Hashtags', 'Item']]\n",
        "\n",
        "    # Step 4: Collaborative filtering recommendations using SVD\n",
        "    collaborative_scores = {}\n",
        "\n",
        "    for item in content_based_recommendations['Item']:\n",
        "        if item in user_item_matrix.columns:\n",
        "            # Find the index of the item in the item_factors matrix\n",
        "            item_index = user_item_matrix.columns.get_loc(item)\n",
        "\n",
        "            # Calculate similarity with other items using collaborative filtering\n",
        "            item_vector = item_factors[:, item_index]\n",
        "            item_similarities = cosine_similarity(item_vector.reshape(1, -1), item_factors.T).flatten()\n",
        "            top_item_indices = item_similarities.argsort()[-(top_n+1):-1][::-1]\n",
        "\n",
        "            for idx in top_item_indices:\n",
        "                recommended_item = user_item_matrix.columns[idx]\n",
        "                collaborative_scores[recommended_item] = collaborative_scores.get(recommended_item, 0) + item_similarities[idx]\n",
        "\n",
        "    # Step 5: Combine content-based and collaborative recommendations\n",
        "    final_recommendations = {}\n",
        "\n",
        "    for item in content_based_recommendations['Item']:\n",
        "        final_recommendations[item] = 0.7 * content_similarity_scores[content_top_indices[content_based_recommendations['Item'].values == item][0]] + \\\n",
        "                                       0.3 * collaborative_scores.get(item, 0)\n",
        "\n",
        "    # Sort final recommendations based on combined scores\n",
        "    sorted_recommendations = sorted(final_recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Prepare the final recommendation output\n",
        "    recommended_items = [(item, df.loc[df['Item'] == item, ['Caption', 'Hashtags']].values[0]) for item, _ in sorted_recommendations]\n",
        "\n",
        "    return recommended_items\n",
        "\n",
        "# Example usage: New user clicked on a caption\n",
        "clicked_caption = \"what is life\"\n",
        "recommendations = recommend_based_on_click(\n",
        "    clicked_caption, df, user_item_matrix, user_factors, item_factors, vectorizer\n",
        ")\n",
        "\n",
        "# Display the recommendations\n",
        "print(\"Recommended Captions and Hashtags:\")\n",
        "for item, details in recommendations:\n",
        "    # print(f\"Caption: {details[0]}\\n Hashtags: {details[1]}\\n Item: {item}\")\n",
        "     print(f\"Caption: {details[0]}\\n\\nHashtags: {details[1]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save SVD model\n",
        "with open('svd_model.pkl', 'wb') as svd_file:\n",
        "    pickle.dump(svd, svd_file)\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer_cr.pkl', 'wb') as tfidf_file:\n",
        "    pickle.dump(vectorizer, tfidf_file)\n",
        "\n",
        "# Save User-Item Matrix\n",
        "user_item_matrix.to_pickle('user_item_matrix.pkl')\n",
        "\n",
        "# Save User Factors and Item Factors\n",
        "with open('user_factors.pkl', 'wb') as user_factors_file:\n",
        "    pickle.dump(user_factors, user_factors_file)\n",
        "\n",
        "with open('item_factors.pkl', 'wb') as item_factors_file:\n",
        "    pickle.dump(item_factors, item_factors_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load SVD model\n",
        "with open('svd_model.pkl', 'rb') as svd_file:\n",
        "    svd = pickle.load(svd_file)\n",
        "\n",
        "# Load TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer_cr.pkl', 'rb') as tfidf_file:\n",
        "    vectorizer = pickle.load(tfidf_file)\n",
        "\n",
        "# Load User-Item Matrix\n",
        "user_item_matrix = pd.read_pickle('user_item_matrix.pkl')\n",
        "\n",
        "# Load User Factors and Item Factors\n",
        "with open('user_factors.pkl', 'rb') as user_factors_file:\n",
        "    user_factors = pickle.load(user_factors_file)\n",
        "\n",
        "with open('item_factors.pkl', 'rb') as item_factors_file:\n",
        "    item_factors = pickle.load(item_factors_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "I2Ab23-PW2KE",
        "outputId": "bd055a44-623e-449c-a04b-1222ada7f2de"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'instagram_reach.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Create a User-Item matrix where rows are users and columns are items (captions + hashtags)\n",
        "user_item_matrix = df.pivot_table(index='USERNAME', columns='Item', values='Likes', fill_value=0)\n",
        "\n",
        "# Step 2: Use SVD for collaborative filtering\n",
        "svd = TruncatedSVD(n_components=50)  # Reduce to 50 latent factors\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "item_factors = svd.components_\n",
        "\n",
        "# Function to recommend captions and hashtags based on a clicked caption\n",
        "def recommend_based_on_clicked_caption(clicked_caption, df, user_item_matrix, item_factors, top_n=5):\n",
        "    # Step 1: Find the index of the clicked caption in the user-item matrix\n",
        "    if clicked_caption not in user_item_matrix.columns:\n",
        "        print(\"Caption not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    item_index = user_item_matrix.columns.get_loc(clicked_caption)\n",
        "\n",
        "    # Step 2: Calculate similarity scores of the clicked item with all other items\n",
        "    item_vector = item_factors[:, item_index]\n",
        "    item_similarities = cosine_similarity(item_vector.reshape(1, -1), item_factors.T).flatten()\n",
        "\n",
        "    # Step 3: Get the indices of the most similar items based on collaborative filtering\n",
        "    similar_item_indices = item_similarities.argsort()[-(top_n + 1):-1][::-1]\n",
        "\n",
        "    # Prepare the final recommendation output\n",
        "    recommended_items = []\n",
        "\n",
        "    for idx in similar_item_indices:\n",
        "        recommended_item = user_item_matrix.columns[idx]\n",
        "        recommended_items.append((recommended_item, df.loc[df['Item'] == recommended_item, ['Caption', 'Hashtags']].values[0]))\n",
        "\n",
        "    return recommended_items\n",
        "\n",
        "# Example usage: New user clicked on a caption\n",
        "clicked_caption = \"Learning about AI and Data Science!\"\n",
        "recommendations = recommend_based_on_clicked_caption(\n",
        "    clicked_caption, df, user_item_matrix, item_factors\n",
        ")\n",
        "\n",
        "# Display the recommendations\n",
        "print(\"Recommended Captions and Hashtags:\")\n",
        "for item, details in recommendations:\n",
        "    print(f\"Caption: {details[0]}\\nHashtags: {details[1]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G6Gx33OnWlrI"
      },
      "outputs": [],
      "source": [
        "# Detailed Explanation of How It Works\n",
        "# Data Preparation:\n",
        "\n",
        "# Combining Captions and Hashtags: The first step combines the Caption and Hashtags into a single column named Item. This allows for a unified approach when calculating similarities later on.\n",
        "# Creating the User-Item Matrix:\n",
        "\n",
        "# A pivot table is created where each row represents a user, each column represents an item (a combination of captions and hashtags), and the values represent the likes for those items. If a user has not liked a particular item, it is filled with 0.\n",
        "# Collaborative Filtering Using SVD:\n",
        "\n",
        "# Truncated SVD: Singular Value Decomposition reduces the dimensions of the user-item matrix into latent factors. This helps identify patterns in user preferences without needing to analyze the entire matrix directly.\n",
        "# User Factors: This results in a matrix that represents users in a reduced latent space.\n",
        "# Item Factors: The item factors matrix represents items in the same latent space. These factors capture underlying relationships between users and items.\n",
        "# Content-Based Filtering Using TF-IDF:\n",
        "\n",
        "# TF-IDF Vectorization: The Item column is converted into a TF-IDF matrix. TF-IDF scores reflect how important a word is to a document in a collection, emphasizing more distinctive terms.\n",
        "# Cosine Similarity Calculation: The cosine similarity is computed between the clicked caption (transformed into TF-IDF) and the item matrix, allowing us to find how similar other items are to the clicked caption.\n",
        "# Generating Recommendations:\n",
        "\n",
        "# Content-Based Recommendations: The top similar items are identified based on content similarity. This gives us a starting point for recommendations based on the user's interest.\n",
        "# Collaborative Recommendations: For each content-based recommended item:\n",
        "# The index of the item is found in the user-item matrix.\n",
        "# The corresponding item vector from the item factors is retrieved.\n",
        "# Similarities to other items are calculated, and scores are aggregated.\n",
        "# Combining Scores:\n",
        "\n",
        "# Final Recommendations: The final recommendations are generated by combining scores from both content and collaborative filtering. The content score is weighted more heavily (0.7) than the collaborative score (0.3) in this example.\n",
        "# Sorting Recommendations: The items are then sorted based on the combined score, ensuring that the most relevant recommendations are presented first.\n",
        "# Output: The function returns a list of recommended items, including their captions and hashtags, formatted for easy readability."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
