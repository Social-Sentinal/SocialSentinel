{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBeGJhHzFmEY",
        "outputId": "9e4cb210-7c03-4b3a-a77a-7aff242d5eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               Caption  \\\n",
            "134  here are some of the best python certification...   \n",
            "137  178 python projects with source code solved an...   \n",
            "163  heres how to create an age calculator using py...   \n",
            "158  180 python projects with source code solved an...   \n",
            "172  a data science project report is a document us...   \n",
            "\n",
            "                                              Hashtags  Likes  Shares  \n",
            "134  #python #pythonprogramming #pythoncode #python...   1623     332  \n",
            "137  #python#pythonprogramming#pythoncode#pythonlea...   1798     472  \n",
            "163  #python#pythonprogramming#pythoncode#pythonlea...   2091     175  \n",
            "158  #python#pythonprogramming#pythoncode#pythonlea...   1421     205  \n",
            "172  #datascience#datasciencejobs#datasciencetraini...   1013     148  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Instagram_data.csv')\n",
        "\n",
        "# Remove duplicates and handle missing values\n",
        "data = data.drop_duplicates().dropna()\n",
        "\n",
        "# Ensure that captions and hashtags are in the correct format\n",
        "data['Caption'] = data['Caption'].str.replace('[^a-zA-Z0-9 #]', '', regex=True).str.lower()\n",
        "data['Hashtags'] = data['Hashtags'].str.replace('[^a-zA-Z0-9 #]', '', regex=True).str.lower()\n",
        "\n",
        "# Function to get top posts based on likes, shares, comments, and saves\n",
        "def get_top_posts(num_recommendations=5):\n",
        "    # Check if the required columns are in the dataset\n",
        "    required_columns = ['Likes', 'Shares', 'Comments', 'Saves', 'Caption', 'Hashtags']\n",
        "    for col in required_columns:\n",
        "        if col not in data.columns:\n",
        "            raise ValueError(f\"Column '{col}' is not present in the data.\")\n",
        "\n",
        "    # Calculate total engagement\n",
        "    data['total_engagement'] = data['Likes'] + data['Shares'] + data['Comments'] + data['Saves']\n",
        "\n",
        "    # Sort the data based on total engagement\n",
        "    top_posts = data[['Caption', 'Hashtags', 'Likes', 'Shares', 'Comments', 'Saves', 'total_engagement']].sort_values(\n",
        "        by='total_engagement', ascending=False\n",
        "    ).head(num_recommendations)\n",
        "\n",
        "    return top_posts[['Caption', 'Hashtags', 'Likes', 'Shares']]\n",
        "\n",
        "# Example usage\n",
        "recommendations = get_top_posts(num_recommendations=5)\n",
        "print(recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 354.7900\n",
            "                                               Caption  \\\n",
            "128  here are some of the best data science certifi...   \n",
            "131  30 data analysis projects solved and explained...   \n",
            "134  here are some of the best python certification...   \n",
            "137  178 python projects with source code solved an...   \n",
            "148  here are some of the best machine learning cer...   \n",
            "\n",
            "                                              Hashtags  Likes  Comments  \n",
            "128  #datascience#datasciencejobs#datasciencetraini...    728         5  \n",
            "131  #dataanalysis#dataanalytics#dataanalyst#python...    955        16  \n",
            "134  #python #pythonprogramming #pythoncode #python...   1623        20  \n",
            "137  #python#pythonprogramming#pythoncode#pythonlea...   1798        15  \n",
            "148  #machinelearning#machinelearningalgorithms#dat...   1059        17  \n"
          ]
        }
      ],
      "source": [
        "from surprise import accuracy\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Instagram_data.csv')\n",
        "\n",
        "# Remove duplicates and handle missing values\n",
        "data = data.drop_duplicates().dropna()\n",
        "\n",
        "# Ensure that captions and hashtags are in the correct format\n",
        "data['Caption'] = data['Caption'].str.replace(\n",
        "    '[^a-zA-Z0-9 #]', '', regex=True).str.lower()\n",
        "data['Hashtags'] = data['Hashtags'].str.replace(\n",
        "    '[^a-zA-Z0-9 #]', '', regex=True).str.lower()\n",
        "data['UserID'] = np.arange(len(data))\n",
        "data['PostID'] = data.index\n",
        "\n",
        "def prepare_data_for_cf(data):\n",
        "    # Assuming 'UserID' and 'PostID' are columns in the dataset\n",
        "    interactions = data[['UserID', 'PostID', 'Likes', 'Comments']].copy()\n",
        "    # Create a simple rating based on engagement\n",
        "    interactions['Rating'] = interactions['Likes'] + interactions['Comments']\n",
        "\n",
        "    return interactions\n",
        "\n",
        "\n",
        "# Prepare interaction data\n",
        "interaction_data = prepare_data_for_cf(data)\n",
        "\n",
        "# Set up Surprise dataset\n",
        "reader = Reader(rating_scale=(0, interaction_data['Rating'].max()))\n",
        "surprise_data = Dataset.load_from_df(\n",
        "    interaction_data[['UserID', 'PostID', 'Rating']], reader)\n",
        "\n",
        "# Train-test split\n",
        "trainset, testset = train_test_split(surprise_data, test_size=0.2)\n",
        "\n",
        "# Build SVD model\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "# Predict ratings on the test set\n",
        "predictions = model.test(testset)\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Save the model\n",
        "with open('collaborative_filtering_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "# Function to get top posts based on collaborative filtering\n",
        "\n",
        "\n",
        "def get_top_posts_cf(user_id, num_recommendations=5):\n",
        "    # Get a list of all PostIDs\n",
        "    post_ids = data['PostID'].unique()\n",
        "\n",
        "    # Predict ratings for all posts for the user\n",
        "    predictions = [model.predict(user_id, post_id) for post_id in post_ids]\n",
        "\n",
        "    # Sort predictions based on estimated ratings\n",
        "    top_posts = sorted(predictions, key=lambda x: x.est,\n",
        "                       reverse=True)[:num_recommendations]\n",
        "\n",
        "    # Get post details\n",
        "    top_post_ids = [post[1] for post in top_posts]\n",
        "    recommended_posts = data[data['PostID'].isin(\n",
        "        top_post_ids)][['Caption', 'Hashtags', 'Likes', 'Comments']]\n",
        "\n",
        "    return recommended_posts\n",
        "\n",
        "\n",
        "# Example usage\n",
        "user_id = 'example_user_id'  # Replace with actual User ID\n",
        "recommendations = get_top_posts_cf(user_id, num_recommendations=5)\n",
        "print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Impressions</th>\n",
              "      <th>From Home</th>\n",
              "      <th>From Hashtags</th>\n",
              "      <th>From Explore</th>\n",
              "      <th>From Other</th>\n",
              "      <th>Saves</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Shares</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Profile Visits</th>\n",
              "      <th>Follows</th>\n",
              "      <th>Conversion Rate</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>UserID</th>\n",
              "      <th>PostID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-12-10</td>\n",
              "      <td>3920</td>\n",
              "      <td>2586</td>\n",
              "      <td>1028</td>\n",
              "      <td>619</td>\n",
              "      <td>56</td>\n",
              "      <td>98</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>162</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>5.714286</td>\n",
              "      <td>here are some of the most important data visua...</td>\n",
              "      <td>#finance#money#business#investing#investment#t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-12-11</td>\n",
              "      <td>5394</td>\n",
              "      <td>2727</td>\n",
              "      <td>1838</td>\n",
              "      <td>1174</td>\n",
              "      <td>78</td>\n",
              "      <td>194</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>224</td>\n",
              "      <td>48</td>\n",
              "      <td>10</td>\n",
              "      <td>20.833333</td>\n",
              "      <td>here are some of the best data science project...</td>\n",
              "      <td>#healthcare#health#covid#data#datascience#data...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-12-12</td>\n",
              "      <td>4021</td>\n",
              "      <td>2085</td>\n",
              "      <td>1188</td>\n",
              "      <td>0</td>\n",
              "      <td>533</td>\n",
              "      <td>41</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>131</td>\n",
              "      <td>62</td>\n",
              "      <td>12</td>\n",
              "      <td>19.354839</td>\n",
              "      <td>learn how to train a machine learning model an...</td>\n",
              "      <td>#data#datascience#dataanalysis#dataanalytics#d...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-12-13</td>\n",
              "      <td>4528</td>\n",
              "      <td>2700</td>\n",
              "      <td>621</td>\n",
              "      <td>932</td>\n",
              "      <td>73</td>\n",
              "      <td>172</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>213</td>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "      <td>34.782609</td>\n",
              "      <td>heres how you can write a python program to de...</td>\n",
              "      <td>#python#pythonprogramming#pythonprojects#pytho...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  Impressions  From Home  From Hashtags  From Explore  \\\n",
              "0  2021-12-10         3920       2586           1028           619   \n",
              "1  2021-12-11         5394       2727           1838          1174   \n",
              "2  2021-12-12         4021       2085           1188             0   \n",
              "3  2021-12-13         4528       2700            621           932   \n",
              "\n",
              "   From Other  Saves  Comments  Shares  Likes  Profile Visits  Follows  \\\n",
              "0          56     98         9       5    162              35        2   \n",
              "1          78    194         7      14    224              48       10   \n",
              "2         533     41        11       1    131              62       12   \n",
              "3          73    172        10       7    213              23        8   \n",
              "\n",
              "   Conversion Rate                                            Caption  \\\n",
              "0         5.714286  here are some of the most important data visua...   \n",
              "1        20.833333  here are some of the best data science project...   \n",
              "2        19.354839  learn how to train a machine learning model an...   \n",
              "3        34.782609  heres how you can write a python program to de...   \n",
              "\n",
              "                                            Hashtags  UserID  PostID  \n",
              "0  #finance#money#business#investing#investment#t...       0       0  \n",
              "1  #healthcare#health#covid#data#datascience#data...       1       1  \n",
              "2  #data#datascience#dataanalysis#dataanalytics#d...       2       2  \n",
              "3  #python#pythonprogramming#pythonprojects#pytho...       3       3  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 205.8469\n",
            "RMSE: 205.8468584473736\n",
            "                                               Caption  \\\n",
            "131  30 data analysis projects solved and explained...   \n",
            "134  here are some of the best python certification...   \n",
            "137  178 python projects with source code solved an...   \n",
            "148  here are some of the best machine learning cer...   \n",
            "154  here are some of the best and unique data anal...   \n",
            "\n",
            "                                              Hashtags  Likes  Comments  \n",
            "131  #dataanalysis#dataanalytics#dataanalyst#python...    955        16  \n",
            "134  #python #pythonprogramming #pythoncode #python...   1623        20  \n",
            "137  #python#pythonprogramming#pythoncode#pythonlea...   1798        15  \n",
            "148  #machinelearning#machinelearningalgorithms#dat...   1059        17  \n",
            "154  #dataanalysis#dataanalytics#dataanalyst#python...    887        15  \n"
          ]
        }
      ],
      "source": [
        "from surprise import accuracy\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "import pickle\n",
        "import numpy as np\n",
        "import uuid\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Instagram_data.csv')\n",
        "\n",
        "# Remove duplicates and handle missing values\n",
        "data = data.drop_duplicates().dropna()\n",
        "\n",
        "# Ensure that captions and hashtags are in the correct format\n",
        "data['Caption'] = data['Caption'].str.replace(\n",
        "    '[^a-zA-Z0-9 #]', '', regex=True).str.lower()\n",
        "data['Hashtags'] = data['Hashtags'].str.replace(\n",
        "    '[^a-zA-Z0-9 #]', '', regex=True).str.lower()\n",
        "\n",
        "# Create unique UserID\n",
        "# Generating a unique UserID for each entry\n",
        "data['UserID'] = np.arange(len(data))\n",
        "\n",
        "# Create unique random PostID using UUID\n",
        "data['PostID'] = [uuid.uuid4().hex for _ in range(len(data))\n",
        "                  ]  # Generate random PostID\n",
        "\n",
        "# Function to prepare dataset for collaborative filtering\n",
        "\n",
        "\n",
        "def prepare_data_for_cf(data):\n",
        "    # Prepare interaction data with UserID, PostID, and engagement score\n",
        "    interactions = data[['UserID', 'PostID', 'Likes', 'Comments']].copy()\n",
        "    # Create a simple rating based on engagement\n",
        "    interactions['Rating'] = interactions['Likes'] + interactions['Comments']\n",
        "\n",
        "    return interactions\n",
        "\n",
        "\n",
        "# Prepare interaction data\n",
        "interaction_data = prepare_data_for_cf(data)\n",
        "\n",
        "# Set up Surprise dataset\n",
        "reader = Reader(rating_scale=(0, interaction_data['Rating'].max()))\n",
        "surprise_data = Dataset.load_from_df(\n",
        "    interaction_data[['UserID', 'PostID', 'Rating']], reader)\n",
        "\n",
        "# Train-test split\n",
        "trainset, testset = train_test_split(surprise_data, test_size=0.2)\n",
        "\n",
        "# Build SVD model\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "# Predict ratings on the test set\n",
        "predictions = model.test(testset)\n",
        "print(f\"RMSE: {accuracy.rmse(predictions)}\")\n",
        "\n",
        "# Save the model\n",
        "with open('collaborative_filtering_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "# Function to get top posts based on collaborative filtering\n",
        "\n",
        "\n",
        "def get_top_posts_cf(user_id, num_recommendations=5):\n",
        "    # Get a list of all PostIDs\n",
        "    post_ids = data['PostID'].unique()\n",
        "\n",
        "    # Predict ratings for all posts for the user\n",
        "    predictions = [model.predict(user_id, post_id) for post_id in post_ids]\n",
        "\n",
        "    # Sort predictions based on estimated ratings\n",
        "    top_posts = sorted(predictions, key=lambda x: x.est,\n",
        "                       reverse=True)[:num_recommendations]\n",
        "\n",
        "    # Get post details\n",
        "    top_post_ids = [post[1] for post in top_posts]\n",
        "    recommended_posts = data[data['PostID'].isin(\n",
        "        top_post_ids)][['Caption', 'Hashtags', 'Likes', 'Comments']]\n",
        "\n",
        "    return recommended_posts\n",
        "\n",
        "\n",
        "# Example usage\n",
        "user_id = 0  # Since we've created a unique UserID, we can use 0 for the first user\n",
        "recommendations = get_top_posts_cf(user_id, num_recommendations=5)\n",
        "print(recommendations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
