{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-fOm4nrTWvU",
        "outputId": "8f0dff40-cc5b-4c97-b3f2-bf1d6fd0117d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommended Captions and Hashtags:\n",
            "Caption: Tag him who promised to help you but he doesn't ðŸ˜’.ðŸ˜‚\n",
            "\n",
            "Hashtags: #artificialintelligenceÂ #ai#machinelearning#deeplearningÂ #algorithmÂ #algorithmsÂ #cs#mlÂ #blockchainÂ #sopia#robotsÂ #project#aiproject#tag#it#boats#artificialintelligenceaiÂ #githubÂ #dataÂ #pythonÂ #RÂ #coding#programmingÂ #coderÂ #programmer\n",
            "\n",
            "Caption: 4K Ai\n",
            "\n",
            "Hashtags: #developerÂ #codingÂ #programmerÂ #javascriptÂ #programmingÂ #softwareÂ #php#webdeveloperÂ #computerscienceÂ #htmlÂ #cssÂ #webdevelopmentÂ #javaÂ #coderÂ #html5#webdevÂ #backendÂ #programmersÂ #softwaredeveloperÂ #softwareengineeringÂ #python#webdesignÂ #frontendÂ #developmentÂ #css3Â #wordpressÂ #codeÂ #webdesignerÂ #js\n",
            "\n",
            "Caption: Love coaching these boys! Hard working, dedicated, and willing to learn. Already one of the best teams in Salford.\n",
            "\n",
            "Hashtags: #grassrootsÂ #development#kidsplayingfootballÂ #kidslearning#kidshavingfunÂ #manchesterfaÂ #salford#delasalletournamentÂ #montonÂ #properclub#doingthingstherightwayÂ #montonsports#u6sÂ #newgeneration\n",
            "\n",
            "Caption: Just an average day for a programmer ðŸ˜–Â #workthroughitÂ .\n",
            "\n",
            "Hashtags: #webdevelopmentÂ #codingÂ #programming#codinglifeÂ #codeÂ #100daysofcodeÂ #java#programmerhumorÂ #javascriptÂ #html#cursosbarcelonaÂ #berlinÂ #css#datascienceÂ #stemÂ #workgoals#officegoalsÂ #learningÂ #machinelearning#getitdoneÂ #anotherdayÂ #instagood#dataanalysisÂ #educationÂ #motivation#barcelonaÂ #careersÂ #careeradvice\n",
            "\n",
            "Caption: 256/365 - Ski Goggles\n",
            "\n",
            "Hashtags: #sketchadayÂ #sketchingÂ #sketchbook#sketchÂ #drawingÂ #artÂ #illustrationÂ #marker#renderingÂ #touchÂ #photography#photoofthedayÂ #pictureÂ #picoftheday#instagoodÂ #instasketchÂ #likeÂ #loveÂ #follow#industrialdesignÂ #productdesignÂ #product#designÂ #ideationÂ #toolsÂ #instilldesign\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/instagram_reach.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Combine Captions and Hashtags into a single \"Item\" column for simplicity\n",
        "df['Item'] = df['Caption'].fillna('') + \" \" + df['Hashtags'].fillna('')\n",
        "\n",
        "# Step 2: Create a pivot table (User-Item matrix) where rows are users and columns are items (captions + hashtags)\n",
        "user_item_matrix = df.pivot_table(index='USERNAME', columns='Item', values='Likes', fill_value=0)\n",
        "\n",
        "# Step 3: Use SVD for collaborative filtering\n",
        "svd = TruncatedSVD(n_components=50)  # Reduce to 50 latent factors\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "item_factors = svd.components_\n",
        "\n",
        "# Step 4: Initialize the TF-IDF vectorizer for content-based filtering\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "item_matrix = vectorizer.fit_transform(df['Item'].values.astype('U'))  # Fit on entire dataset\n",
        "\n",
        "# Function to recommend captions and hashtags based on a clicked caption\n",
        "def recommend_based_on_click(clicked_caption, df, user_item_matrix, user_factors, item_factors, vectorizer, top_n=5):\n",
        "    # Step 1: Transform the clicked caption using the TF-IDF vectorizer\n",
        "    clicked_caption_vector = vectorizer.transform([clicked_caption])\n",
        "\n",
        "    # Step 2: Calculate content similarity between the clicked caption and the items in the dataset\n",
        "    content_similarity_scores = cosine_similarity(clicked_caption_vector, item_matrix).flatten()\n",
        "\n",
        "    # Step 3: Get the indices of the most similar captions based on content\n",
        "    content_top_indices = content_similarity_scores.argsort()[-(top_n+1):-1][::-1]\n",
        "    content_based_recommendations = df.iloc[content_top_indices][['Caption', 'Hashtags', 'Item']]\n",
        "\n",
        "    # Step 4: Collaborative filtering recommendations using SVD\n",
        "    collaborative_scores = {}\n",
        "\n",
        "    for item in content_based_recommendations['Item']:\n",
        "        if item in user_item_matrix.columns:\n",
        "            # Find the index of the item in the item_factors matrix\n",
        "            item_index = user_item_matrix.columns.get_loc(item)\n",
        "\n",
        "            # Calculate similarity with other items using collaborative filtering\n",
        "            item_vector = item_factors[:, item_index]\n",
        "            item_similarities = cosine_similarity(item_vector.reshape(1, -1), item_factors.T).flatten()\n",
        "            top_item_indices = item_similarities.argsort()[-(top_n+1):-1][::-1]\n",
        "\n",
        "            for idx in top_item_indices:\n",
        "                recommended_item = user_item_matrix.columns[idx]\n",
        "                collaborative_scores[recommended_item] = collaborative_scores.get(recommended_item, 0) + item_similarities[idx]\n",
        "\n",
        "    # Step 5: Combine content-based and collaborative recommendations\n",
        "    final_recommendations = {}\n",
        "\n",
        "    for item in content_based_recommendations['Item']:\n",
        "        final_recommendations[item] = 0.7 * content_similarity_scores[content_top_indices[content_based_recommendations['Item'].values == item][0]] + \\\n",
        "                                       0.3 * collaborative_scores.get(item, 0)\n",
        "\n",
        "    # Sort final recommendations based on combined scores\n",
        "    sorted_recommendations = sorted(final_recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Prepare the final recommendation output\n",
        "    recommended_items = [(item, df.loc[df['Item'] == item, ['Caption', 'Hashtags']].values[0]) for item, _ in sorted_recommendations]\n",
        "\n",
        "    return recommended_items\n",
        "\n",
        "# Example usage: New user clicked on a caption\n",
        "clicked_caption = \"i love coding\"\n",
        "recommendations = recommend_based_on_click(\n",
        "    clicked_caption, df, user_item_matrix, user_factors, item_factors, vectorizer\n",
        ")\n",
        "\n",
        "# Display the recommendations\n",
        "print(\"Recommended Captions and Hashtags:\")\n",
        "for item, details in recommendations:\n",
        "    # print(f\"Caption: {details[0]}\\n Hashtags: {details[1]}\\n Item: {item}\")\n",
        "     print(f\"Caption: {details[0]}\\n\\nHashtags: {details[1]}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHpEjR3NTZv4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Gx33OnWlrI"
      },
      "outputs": [],
      "source": [
        "# Detailed Explanation of How It Works\n",
        "# Data Preparation:\n",
        "\n",
        "# Combining Captions and Hashtags: The first step combines the Caption and Hashtags into a single column named Item. This allows for a unified approach when calculating similarities later on.\n",
        "# Creating the User-Item Matrix:\n",
        "\n",
        "# A pivot table is created where each row represents a user, each column represents an item (a combination of captions and hashtags), and the values represent the likes for those items. If a user has not liked a particular item, it is filled with 0.\n",
        "# Collaborative Filtering Using SVD:\n",
        "\n",
        "# Truncated SVD: Singular Value Decomposition reduces the dimensions of the user-item matrix into latent factors. This helps identify patterns in user preferences without needing to analyze the entire matrix directly.\n",
        "# User Factors: This results in a matrix that represents users in a reduced latent space.\n",
        "# Item Factors: The item factors matrix represents items in the same latent space. These factors capture underlying relationships between users and items.\n",
        "# Content-Based Filtering Using TF-IDF:\n",
        "\n",
        "# TF-IDF Vectorization: The Item column is converted into a TF-IDF matrix. TF-IDF scores reflect how important a word is to a document in a collection, emphasizing more distinctive terms.\n",
        "# Cosine Similarity Calculation: The cosine similarity is computed between the clicked caption (transformed into TF-IDF) and the item matrix, allowing us to find how similar other items are to the clicked caption.\n",
        "# Generating Recommendations:\n",
        "\n",
        "# Content-Based Recommendations: The top similar items are identified based on content similarity. This gives us a starting point for recommendations based on the user's interest.\n",
        "# Collaborative Recommendations: For each content-based recommended item:\n",
        "# The index of the item is found in the user-item matrix.\n",
        "# The corresponding item vector from the item factors is retrieved.\n",
        "# Similarities to other items are calculated, and scores are aggregated.\n",
        "# Combining Scores:\n",
        "\n",
        "# Final Recommendations: The final recommendations are generated by combining scores from both content and collaborative filtering. The content score is weighted more heavily (0.7) than the collaborative score (0.3) in this example.\n",
        "# Sorting Recommendations: The items are then sorted based on the combined score, ensuring that the most relevant recommendations are presented first.\n",
        "# Output: The function returns a list of recommended items, including their captions and hashtags, formatted for easy readability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy4wvfvA5dJZ",
        "outputId": "9093ef1e-2ebb-4bc3-a1b1-3a7b56647b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Item not found in the dataset.\n",
            "Recommended Captions and Hashtags:\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.decomposition import TruncatedSVD\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# # Load the sentiments dataset\n",
        "# file_path = '/content/sentiments.csv'\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Step 1: Combine Captions and Hashtags into a single \"Item\" column\n",
        "# df['Item'] = df['caption'].fillna('') + \" \" + df['hashtags'].fillna('')\n",
        "\n",
        "# # Step 2: Create a User-Item matrix where rows are users and columns are items (post_id or Item)\n",
        "# # We use 'likes' and 'shares' as interaction values. Adjust this depending on what you prefer to use.\n",
        "# user_item_matrix = df.pivot_table(index='user_id', columns='Item', values='likes', fill_value=0)\n",
        "\n",
        "# # Step 3: Apply SVD for collaborative filtering\n",
        "# svd = TruncatedSVD(n_components=50)  # Reduce the dimensionality to 50 latent factors\n",
        "# user_factors = svd.fit_transform(user_item_matrix)\n",
        "# item_factors = svd.components_\n",
        "\n",
        "# # Function to recommend captions and hashtags for a new user based on a clicked post\n",
        "# def recommend_for_new_user(clicked_item, df, user_item_matrix, item_factors, top_n=5):\n",
        "#     # Step 1: Find the index of the clicked item (post) in the user-item matrix\n",
        "#     if clicked_item not in user_item_matrix.columns:\n",
        "#         print(\"Item not found in the dataset.\")\n",
        "#         return []\n",
        "\n",
        "#     item_index = user_item_matrix.columns.get_loc(clicked_item)\n",
        "\n",
        "#     # Step 2: Calculate similarity scores between the clicked item and all other items\n",
        "#     item_vector = item_factors[:, item_index]\n",
        "#     item_similarities = cosine_similarity(item_vector.reshape(1, -1), item_factors.T).flatten()\n",
        "\n",
        "#     # Step 3: Get the indices of the most similar items based on collaborative filtering\n",
        "#     similar_item_indices = item_similarities.argsort()[-(top_n + 1):-1][::-1]\n",
        "\n",
        "#     # Prepare the final recommendation output\n",
        "#     recommended_items = []\n",
        "\n",
        "#     for idx in similar_item_indices:\n",
        "#         recommended_item = user_item_matrix.columns[idx]\n",
        "#         caption_and_hashtags = df.loc[df['Item'] == recommended_item, ['caption', 'hashtags']].values[0]\n",
        "#         recommended_items.append((recommended_item, caption_and_hashtags))\n",
        "\n",
        "#     return recommended_items\n",
        "\n",
        "# # Example usage: New user clicked on a post/caption\n",
        "# clicked_item = \"i want to do projects in ai\"  # Change this to a valid caption from your dataset\n",
        "# recommendations = recommend_for_new_user(\n",
        "#     clicked_item, df, user_item_matrix, item_factors\n",
        "# )\n",
        "\n",
        "# # Display the recommendations\n",
        "# print(\"Recommended Captions and Hashtags:\")\n",
        "# for item, details in recommendations:\n",
        "#     print(f\"Caption: {details[0]}\\nHashtags: {details[1]}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'instagram_reach.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Combine Captions and Hashtags into a single \"Item\" column for simplicity\n",
        "df['Item'] = df['Caption'].fillna('') + \" \" + df['Hashtags'].fillna('')\n",
        "\n",
        "# Step 2: Create a pivot table (User-Item matrix) where rows are users and columns are items (captions + hashtags)\n",
        "user_item_matrix = df.pivot_table(\n",
        "    index='USERNAME', columns='Item', values='Likes', fill_value=0)\n",
        "\n",
        "# Step 3: Use SVD for collaborative filtering\n",
        "svd = TruncatedSVD(n_components=50)  # Reduce to 50 latent factors\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "item_factors = svd.components_\n",
        "\n",
        "# Step 4: Initialize the TF-IDF vectorizer for content-based filtering\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "item_matrix = vectorizer.fit_transform(\n",
        "    df['Item'].values.astype('U'))  # Fit on entire dataset\n",
        "\n",
        "# Function to recommend captions and hashtags based on a clicked caption\n",
        "\n",
        "\n",
        "def recommend_based_on_click(clicked_caption, df, user_item_matrix, user_factors, item_factors, vectorizer, top_n=5):\n",
        "    # Step 1: Transform the clicked caption using the TF-IDF vectorizer\n",
        "    clicked_caption_vector = vectorizer.transform([clicked_caption])\n",
        "\n",
        "    # Step 2: Calculate content similarity between the clicked caption and the items in the dataset\n",
        "    content_similarity_scores = cosine_similarity(\n",
        "        clicked_caption_vector, item_matrix).flatten()\n",
        "\n",
        "    # Step 3: Get the indices of the most similar captions based on content\n",
        "    content_top_indices = content_similarity_scores.argsort(\n",
        "    )[-(top_n+1):-1][::-1]\n",
        "    content_based_recommendations = df.iloc[content_top_indices][[\n",
        "        'Caption', 'Hashtags', 'Item']]\n",
        "\n",
        "    # Step 4: Collaborative filtering recommendations using SVD\n",
        "    collaborative_scores = {}\n",
        "\n",
        "    for item in content_based_recommendations['Item']:\n",
        "        if item in user_item_matrix.columns:\n",
        "            # Find the index of the item in the item_factors matrix\n",
        "            item_index = user_item_matrix.columns.get_loc(item)\n",
        "\n",
        "            # Calculate similarity with other items using collaborative filtering\n",
        "            item_vector = item_factors[:, item_index]\n",
        "            item_similarities = cosine_similarity(\n",
        "                item_vector.reshape(1, -1), item_factors.T).flatten()\n",
        "            top_item_indices = item_similarities.argsort()[-(top_n+1):-1][::-1]\n",
        "\n",
        "            for idx in top_item_indices:\n",
        "                recommended_item = user_item_matrix.columns[idx]\n",
        "                collaborative_scores[recommended_item] = collaborative_scores.get(\n",
        "                    recommended_item, 0) + item_similarities[idx]\n",
        "\n",
        "    # Step 5: Combine content-based and collaborative recommendations\n",
        "    final_recommendations = {}\n",
        "\n",
        "    for item in content_based_recommendations['Item']:\n",
        "        final_recommendations[item] = 0.7 * content_similarity_scores[content_top_indices[content_based_recommendations['Item'].values == item][0]] + \\\n",
        "            0.3 * collaborative_scores.get(item, 0)\n",
        "\n",
        "    # Sort final recommendations based on combined scores\n",
        "    sorted_recommendations = sorted(\n",
        "        final_recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Prepare the final recommendation output\n",
        "    recommended_items = [(item, df.loc[df['Item'] == item, [\n",
        "                          'Caption', 'Hashtags']].values[0]) for item, _ in sorted_recommendations]\n",
        "\n",
        "    return recommended_items\n",
        "\n",
        "\n",
        "# Example usage: New user clicked on a caption\n",
        "clicked_caption = \"what is life\"\n",
        "recommendations = recommend_based_on_click(\n",
        "    clicked_caption, df, user_item_matrix, user_factors, item_factors, vectorizer\n",
        ")\n",
        "\n",
        "# Display the recommendations\n",
        "print(\"Recommended Captions and Hashtags:\")\n",
        "for item, details in recommendations:\n",
        "    # print(f\"Caption: {details[0]}\\n Hashtags: {details[1]}\\n Item: {item}\")\n",
        "    print(f\"Caption: {details[0]}\\n\\nHashtags: {details[1]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save SVD model\n",
        "with open('svd_model.pkl', 'wb') as svd_file:\n",
        "    pickle.dump(svd, svd_file)\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer_cr.pkl', 'wb') as tfidf_file:\n",
        "    pickle.dump(vectorizer, tfidf_file)\n",
        "\n",
        "# Save User-Item Matrix\n",
        "user_item_matrix.to_pickle('user_item_matrix.pkl')\n",
        "\n",
        "# Save User Factors and Item Factors\n",
        "with open('user_factors.pkl', 'wb') as user_factors_file:\n",
        "    pickle.dump(user_factors, user_factors_file)\n",
        "\n",
        "with open('item_factors.pkl', 'wb') as item_factors_file:\n",
        "    pickle.dump(item_factors, item_factors_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load SVD model\n",
        "with open('svd_model.pkl', 'rb') as svd_file:\n",
        "    svd = pickle.load(svd_file)\n",
        "\n",
        "# Load TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer_cr.pkl', 'rb') as tfidf_file:\n",
        "    vectorizer = pickle.load(tfidf_file)\n",
        "\n",
        "# Load User-Item Matrix\n",
        "user_item_matrix = pd.read_pickle('user_item_matrix.pkl')\n",
        "\n",
        "# Load User Factors and Item Factors\n",
        "with open('user_factors.pkl', 'rb') as user_factors_file:\n",
        "    user_factors = pickle.load(user_factors_file)\n",
        "\n",
        "with open('item_factors.pkl', 'rb') as item_factors_file:\n",
        "    item_factors = pickle.load(item_factors_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'instagram_reach.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Create a User-Item matrix where rows are users and columns are items (captions + hashtags)\n",
        "user_item_matrix = df.pivot_table(\n",
        "    index='USERNAME', columns='Item', values='Likes', fill_value=0)\n",
        "\n",
        "# Step 2: Use SVD for collaborative filtering\n",
        "svd = TruncatedSVD(n_components=50)  # Reduce to 50 latent factors\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "item_factors = svd.components_\n",
        "\n",
        "# Function to recommend captions and hashtags based on a clicked caption\n",
        "\n",
        "\n",
        "def recommend_based_on_clicked_caption(clicked_caption, df, user_item_matrix, item_factors, top_n=5):\n",
        "    # Step 1: Find the index of the clicked caption in the user-item matrix\n",
        "    if clicked_caption not in user_item_matrix.columns:\n",
        "        print(\"Caption not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    item_index = user_item_matrix.columns.get_loc(clicked_caption)\n",
        "\n",
        "    # Step 2: Calculate similarity scores of the clicked item with all other items\n",
        "    item_vector = item_factors[:, item_index]\n",
        "    item_similarities = cosine_similarity(\n",
        "        item_vector.reshape(1, -1), item_factors.T).flatten()\n",
        "\n",
        "    # Step 3: Get the indices of the most similar items based on collaborative filtering\n",
        "    similar_item_indices = item_similarities.argsort()[-(top_n + 1):-1][::-1]\n",
        "\n",
        "    # Prepare the final recommendation output\n",
        "    recommended_items = []\n",
        "\n",
        "    for idx in similar_item_indices:\n",
        "        recommended_item = user_item_matrix.columns[idx]\n",
        "        recommended_items.append((recommended_item, df.loc[df['Item'] == recommended_item, [\n",
        "                                 'Caption', 'Hashtags']].values[0]))\n",
        "\n",
        "    return recommended_items\n",
        "\n",
        "\n",
        "# Example usage: New user clicked on a caption\n",
        "clicked_caption = \"Learning about AI and Data Science!\"\n",
        "recommendations = recommend_based_on_clicked_caption(\n",
        "    clicked_caption, df, user_item_matrix, item_factors\n",
        ")\n",
        "\n",
        "# Display the recommendations\n",
        "print(\"Recommended Captions and Hashtags:\")\n",
        "for item, details in recommendations:\n",
        "    print(f\"Caption: {details[0]}\\nHashtags: {details[1]}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
