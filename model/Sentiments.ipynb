{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSsZOKthHKgI",
        "outputId": "95555f0b-19a4-447d-a4f4-9756374447b6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Step 1: Load the CSV file\n",
        "df = pd.read_csv('D:\\Github\\SocialSentinel\\data\\d4\\instagram_reach.csv')\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Keep only relevant columns (Caption, Hashtags)\n",
        "df = df[['Caption', 'Hashtags']]\n",
        "\n",
        "# Remove any missing or NaN values\n",
        "df.dropna(subset=['Caption', 'Hashtags'], inplace=True)\n",
        "\n",
        "# Step 3: Sentiment Analysis Function\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity  # Returns a score between -1 and 1\n",
        "\n",
        "# Step 4: Calculate Sentiment Scores for Caption and Hashtags\n",
        "df['caption_score'] = df['Caption'].apply(analyze_sentiment)\n",
        "df['hashtag_score'] = df['Hashtags'].apply(analyze_sentiment)\n",
        "\n",
        "# Step 5: Combine Scores to Determine Overall Sentiment\n",
        "df['overall_score'] = (df['caption_score'] + df['hashtag_score']) / 2\n",
        "\n",
        "# Step 6: Categorize Sentiment\n",
        "def categorize_sentiment(score):\n",
        "    if score < 0:\n",
        "        return 'Negative'\n",
        "    elif score > 0:\n",
        "        return 'Positive'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "df['sentiment'] = df['overall_score'].apply(categorize_sentiment)\n",
        "\n",
        "# Step 7: Create a new DataFrame with required columns\n",
        "final_df = df[['Caption', 'Hashtags', 'sentiment', 'overall_score']]\n",
        "\n",
        "# Step 8: Save to a new CSV file\n",
        "final_df.to_csv('instagram_reach_with_sentiments.csv', index=False)\n",
        "\n",
        "print(\"Sentiment analysis complete! New file saved as 'instagram_reach_with_sentiments.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnv_xBEuHpuE",
        "outputId": "f3568286-8068-4494-986b-2267f70adb04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original training set shape: Counter({'Positive': 45, 'Neutral': 25, 'Negative': 5})\n",
            "Balanced training set shape: Counter({'Positive': 45, 'Neutral': 45, 'Negative': 45})\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00         2\n",
            "     Neutral       1.00      0.33      0.50         6\n",
            "    Positive       0.65      1.00      0.79        11\n",
            "\n",
            "    accuracy                           0.68        19\n",
            "   macro avg       0.55      0.44      0.43        19\n",
            "weighted avg       0.69      0.68      0.61        19\n",
            "\n",
            "Predicted Sentiment: Positive\n",
            "Predicted Sentiment: Positive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Load the new CSV file\n",
        "df = pd.read_csv('instagram_reach_with_sentiments.csv')\n",
        "\n",
        "# Step 2: Prepare Data for Machine Learning\n",
        "X = df['Caption'] + \" \" + df['Hashtags']  # Features (text data)\n",
        "y = df['sentiment']  # Labels (sentiment categories)\n",
        "\n",
        "# Step 3: Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 4: Convert Text Data into Numerical Features\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Step 5: Use Random Over Sampling to Balance Classes\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_balanced, y_train_balanced = ros.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Original training set shape:\", Counter(y_train))\n",
        "print(\"Balanced training set shape:\", Counter(y_train_balanced))\n",
        "\n",
        "# Step 6: Train a Machine Learning Model (Logistic Regression)\n",
        "model = LogisticRegression(class_weight='balanced')  # Handle class imbalance by adjusting weights\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 8: Make Predictions on New Data\n",
        "def predict_sentiment(new_caption, new_hashtags):\n",
        "    new_text = new_caption + \" \" + new_hashtags\n",
        "    new_tfidf = tfidf.transform([new_text])\n",
        "    return model.predict(new_tfidf)[0]\n",
        "\n",
        "\n",
        "# Example usage\n",
        "new_caption = \"hello\"\n",
        "new_hashtags = \"#programming\"\n",
        "predicted_sentiment = predict_sentiment(new_caption, new_hashtags)\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
        "\n",
        "new_caption = \"The Internet of Things : A Very Short Story.\"\n",
        "new_hashtags = \"#MachineLearning\"\n",
        "predicted_sentiment = predict_sentiment(new_caption, new_hashtags)\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCIxad-KJjGU",
        "outputId": "a3d98af2-208e-4265-ecd1-03ae50e4adff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "new_caption = \"i AM very sad\"\n",
        "new_hashtags = \"sad\"\n",
        "predicted_sentiment = predict_sentiment(new_caption, new_hashtags)\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Using Random Forest for better accuracy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Load the CSV file\n",
        "df = pd.read_csv('D:\\Github\\SocialSentinel\\test\\sentiments.csv')\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Keep only relevant columns (Caption, Hashtags)\n",
        "df = df[['Caption', 'Hashtags']]\n",
        "\n",
        "# Remove any missing or NaN values\n",
        "df.dropna(subset=['Caption', 'Hashtags'], inplace=True)\n",
        "\n",
        "# Step 3: Sentiment Analysis Function\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity \n",
        "\n",
        "\n",
        "# Step 4: Calculate Sentiment Scores for Caption and Hashtags\n",
        "df['caption_score'] = df['Caption'].apply(analyze_sentiment)\n",
        "df['hashtag_score'] = df['Hashtags'].apply(analyze_sentiment)\n",
        "\n",
        "# Step 5: Combine Scores to Determine Overall Sentiment\n",
        "df['overall_score'] = (df['caption_score'] + df['hashtag_score']) / 2\n",
        "\n",
        "# Step 6: Categorize Sentiment\n",
        "\n",
        "def categorize_sentiment(score):\n",
        "    if score < 0:\n",
        "        return 'Negative'\n",
        "    elif score > 0:\n",
        "        return 'Positive'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "\n",
        "df['sentiment'] = df['overall_score'].apply(categorize_sentiment)\n",
        "\n",
        "# Step 7: Create a new DataFrame with required columns\n",
        "final_df = df[['Caption', 'Hashtags', 'sentiment', 'overall_score']]\n",
        "\n",
        "# Step 8: Save to a new CSV file\n",
        "final_df.to_csv('instagram_reach_with_sentiments.csv', index=False)\n",
        "\n",
        "print(\"Sentiment analysis complete! New file saved as 'instagram_reach_with_sentiments.csv'.\")\n",
        "\n",
        "# Load the new CSV file for training the model\n",
        "df = pd.read_csv('instagram_reach_with_sentiments.csv')\n",
        "\n",
        "# Prepare Data for Machine Learning\n",
        "X = df['Caption'] + \" \" + df['Hashtags']  # Features (text data)\n",
        "y = df['sentiment']  # Labels (sentiment categories)\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Convert Text Data into Numerical Features\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Use Random Over Sampling to Balance Classes\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_balanced, y_train_balanced = ros.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Original training set shape:\", Counter(y_train))\n",
        "print(\"Balanced training set shape:\", Counter(y_train_balanced))\n",
        "\n",
        "# Train a Machine Learning Model (Random Forest Classifier)\n",
        "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Save the model and the TF-IDF vectorizer\n",
        "with open('sentiment_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(tfidf, vectorizer_file)\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Make Predictions on New Data\n",
        "def predict_sentiment(new_caption, new_hashtags):\n",
        "    # Load the model and vectorizer\n",
        "    with open('sentiment_model.pkl', 'rb') as model_file:\n",
        "        loaded_model = pickle.load(model_file)\n",
        "\n",
        "    with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
        "        loaded_vectorizer = pickle.load(vectorizer_file)\n",
        "\n",
        "    new_text = new_caption + \" \" + new_hashtags\n",
        "    new_tfidf = loaded_vectorizer.transform([new_text])\n",
        "    return loaded_model.predict(new_tfidf)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "new_caption = \"I am happy\"\n",
        "new_hashtags = \"#MachineLearning\"\n",
        "predicted_sentiment = predict_sentiment(new_caption, new_hashtags)\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'tfidf_vectorizer.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     random_forest_model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(random_forest_model_file)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Load the TF-IDF vectorizer\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mtfidf_vectorizer.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m vectorizer_file:\n\u001b[0;32m     12\u001b[0m     tfidf_vectorizer \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(vectorizer_file)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Define the test data\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tfidf_vectorizer.pkl'"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the Random Forest model\n",
        "with open('sentiment_model.pkl', 'rb') as random_forest_model_file:\n",
        "    random_forest_model = pickle.load(random_forest_model_file)\n",
        "\n",
        "# Load the TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
        "    tfidf_vectorizer = pickle.load(vectorizer_file)\n",
        "\n",
        "# Define the test data\n",
        "test_data = pd.DataFrame(\n",
        "    {'text': ['I love this product', 'This product is terrible']})\n",
        "\n",
        "# Preprocess the text data\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Apply preprocessing\n",
        "test_data['text'] = test_data['text'].apply(preprocess_text)\n",
        "\n",
        "# Vectorize the preprocessed text data\n",
        "X_test = tfidf_vectorizer.transform(test_data['text'])\n",
        "\n",
        "# Make predictions\n",
        "predictions = random_forest_model.predict(X_test)\n",
        "\n",
        "# Print the results\n",
        "for text, prediction in zip(test_data['text'], predictions):\n",
        "    print(f\"Text: '{text}' - Sentiment: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
